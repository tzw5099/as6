{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:57:12.552396Z",
     "start_time": "2018-04-03T10:57:12.544341Z"
    }
   },
   "source": [
    "6:58am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.413380Z",
     "start_time": "2018-04-03T18:58:55.119276Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# COLLAPSE CELL\n",
    "# AMsearch np.v*\n",
    "#x = data['mass']\n",
    "#x?\n",
    "\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='solarized')\n",
    "# from jupyterlab_table import JSONTable\n",
    "# JSONTable(df)\n",
    "\n",
    "from pprint import pprint\n",
    "import math\n",
    "import statsmodels.stats as sms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.regression as smr\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# 04atplotlib inline\n",
    "# %load_ext heat\n",
    "\n",
    "plt.ion()\n",
    "# plt.ioff()\n",
    "\n",
    "# %heat\n",
    "\n",
    "import os \n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.460118Z",
     "start_time": "2018-04-03T18:58:57.436685Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dsi-assessment-2/data/rent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.581512Z",
     "start_time": "2018-04-03T18:58:57.542554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 5, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_lists(list1, list2):\n",
    "    '''\n",
    "    INPUT: list, list\n",
    "    OUTPUT: list\n",
    "\n",
    "    list1 and list2 have the same length. Return a list which contains the\n",
    "    maximum element of each list for every index.\n",
    "    '''\n",
    "    list3 = []\n",
    "    for x in range(len(list1)):\n",
    "        if list1[x]>list2[x]:\n",
    "            list3.append(list1[x])\n",
    "        else:\n",
    "            list3.append(list2[x])\n",
    "    return list3\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "list1 = [2,3,4,5,7]\n",
    "list2 = [4,4,4,4,4]\n",
    "\n",
    "max_lists(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.671493Z",
     "start_time": "2018-04-03T18:58:57.650804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_diagonal(mat):\n",
    "    index_start = mat[0][0]\n",
    "    mat_diag = []\n",
    "    len_mat = len(mat[0])\n",
    "    for x in range(len(mat)):\n",
    "        if len(mat[x]) == len_mat:\n",
    "            mat_diag.append(mat[x][x])\n",
    "        else:\n",
    "            pass\n",
    "    return mat_diag\n",
    "# 0,0\n",
    "# 1,1\n",
    "# 2,2\n",
    "mat = [[1, 2], \n",
    "       [3, 4], \n",
    "       [5, 6, 7]]\n",
    "get_diagonal(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.846422Z",
     "start_time": "2018-04-03T18:58:57.751306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a => 1\n",
      "b => 5\n",
      "c => 1\n",
      "e => 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 7, 'c': 6, 'e': 8, 'f': 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_dictionaries(d1, d2):\n",
    "    '''\n",
    "    INPUT: dictionary, dictionary\n",
    "    OUTPUT: dictionary\n",
    "\n",
    "    Return a new dictionary which contains all the keys from d1 and d2 with\n",
    "    their associated values. If a key is in both dictionaries, the value should\n",
    "    be the sum of the two values.\n",
    "    '''\n",
    "    d3 = {}\n",
    "    both_d1_d2 = list((set(d1).intersection(d2)))\n",
    "    \n",
    "    for (key,val), (k2,v2) in zip(d1.items(), d2.items()):\n",
    "        if any(key in s for s in both_d1_d2):\n",
    "            d3[key] = (d1[key] + d2[key])\n",
    "        else:\n",
    "            d3[key] = val\n",
    "            d3[k2] = v2\n",
    "        print(key, \"=>\", val)        \n",
    "        \n",
    "    return d3\n",
    "\n",
    "    \n",
    "\n",
    "# d1 = {'jack': 4098, 'sape': 4139, 'bill': 24, 'jake': 4}\n",
    "# d2 = {'bob': 4098, 'red': 4139, 'bill': 16, 'jake': 7}\n",
    "\n",
    "# merge_dictionaries(d1,d2)\n",
    "\n",
    "d1 = {\"a\": 1, \"b\": 5, \"c\": 1, \"e\": 8}\n",
    "d2 = {\"b\": 2, \"c\": 5, \"d\": 10, \"f\": 6}\n",
    "merge_dictionaries(d1,d2)\n",
    "\n",
    "# {'a': 1, 'b': 7, 'c': 6, 'e': 8, 'f': 6} <-- output\n",
    "# {'a': 1, 'b': 7, 'c': 6, 'd': 10, 'e': 8, 'f': 6} <-- actual answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:57.917994Z",
     "start_time": "2018-04-03T18:58:57.901835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'b']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((set(d1).intersection(d2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:58.029519Z",
     "start_time": "2018-04-03T18:58:57.975823Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-1fa3f520d4c6>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-1fa3f520d4c6>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    level : int, level name, or sequence of such, default None If the axis is a MultiIndex (hierarchical), group by a particular level or levels as_index : boolean, default True\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def make_char_dict(filename):\n",
    "    '''\n",
    "    INPUT: string\n",
    "    OUTPUT: dictionary (string => list)\n",
    "\n",
    "    Given a file containing rows of text, create a dictionary whose keys\n",
    "    are single characters. The value associated with each key is a list of all\n",
    "    the line numbers which start with that letter. The first line should have\n",
    "    line number 1.  Characters which never are the first letter of a line do\n",
    "    not need to be included in your dictionary.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "level : int, level name, or sequence of such, default None If the axis is a MultiIndex (hierarchical), group by a particular level or levels as_index : boolean, default True\n",
    "\n",
    "For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output\n",
    "\n",
    "sort : boolean, default True\n",
    "\n",
    "Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves the order of rows within each group.\n",
    "\n",
    "group_keys : boolean, default True\n",
    "\n",
    "When calling apply, add group keys to index to identify pieces\n",
    "\n",
    "squeeze : boolean, default False\n",
    "\n",
    "reduce the dimensionality of the return type if possible, otherwise return a consistent type\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:58.036193Z",
     "start_time": "2018-04-03T18:58:56.207Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pandas_add_increase_column(df):\n",
    "    '''\n",
    "    INPUT: DataFrame\n",
    "    OUTPUT: None\n",
    "\n",
    "    Add a column to the DataFrame called 'Increase' which contains the\n",
    "    amount that the median rent increased by from 2011 to 2014.\n",
    "    '''\n",
    "    df['Increase']=((df['med_2014']-df['med_2011'])/df['med_2011'])\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"dsi-assessment-2/data/rent.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T18:58:58.041134Z",
     "start_time": "2018-04-03T18:58:56.388Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pandas_only_given_state(df, state):\n",
    "    '''\n",
    "    INPUT: DataFrame, string\n",
    "    OUTPUT: DataFrame\n",
    "\n",
    "    Return a new pandas DataFrame which contains the entries for the given\n",
    "    state. Only include these columns:\n",
    "        Neighborhood, City, med_2011, med_2014\n",
    "    '''\n",
    "    df_state=df.where(df['State']==state)\n",
    "    df_state=df_state.dropna()\n",
    "    return df_state\n",
    "\n",
    "state = \"TX\"\n",
    "# pandas_only_given_state(df, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T19:15:47.675102Z",
     "start_time": "2018-04-03T19:15:47.471323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>med_2011</th>\n",
       "      <th>med_2014</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Akron</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>690.0</td>\n",
       "      <td>725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>Albany</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albuquerque</th>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexandria</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>VA</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amherst</th>\n",
       "      <td>Amherst</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anaheim</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>CA</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anchorage</th>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arlington</th>\n",
       "      <td>Arlington</td>\n",
       "      <td>VA</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auburn</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>WA</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>1375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Augusta</th>\n",
       "      <td>Augusta</td>\n",
       "      <td>GA</td>\n",
       "      <td>826.0</td>\n",
       "      <td>955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aurora</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>CO</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austin</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bakersfield</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baltimore</th>\n",
       "      <td>Baltimore</td>\n",
       "      <td>MD</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beaverton</th>\n",
       "      <td>Beaverton</td>\n",
       "      <td>OR</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bellevue</th>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>2550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bellingham</th>\n",
       "      <td>Bellingham</td>\n",
       "      <td>WA</td>\n",
       "      <td>879.0</td>\n",
       "      <td>710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bend</th>\n",
       "      <td>Bend</td>\n",
       "      <td>OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boise</th>\n",
       "      <td>Boise</td>\n",
       "      <td>ID</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boulder</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branford</th>\n",
       "      <td>Branford</td>\n",
       "      <td>CT</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo</th>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NY</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambridge</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chandler</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlotte</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlottesville</th>\n",
       "      <td>Charlottesville</td>\n",
       "      <td>VA</td>\n",
       "      <td>875.0</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesapeake</th>\n",
       "      <td>Chesapeake</td>\n",
       "      <td>VA</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satellite Beach</th>\n",
       "      <td>Satellite Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>975.0</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scottsdale</th>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seattle</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>2450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shreveport</th>\n",
       "      <td>Shreveport</td>\n",
       "      <td>LA</td>\n",
       "      <td>815.0</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Bend</th>\n",
       "      <td>South Bend</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sparta</th>\n",
       "      <td>Sparta</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spokane</th>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Springfield</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stamford</th>\n",
       "      <td>Stamford</td>\n",
       "      <td>CT</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stockton</th>\n",
       "      <td>Stockton</td>\n",
       "      <td>CA</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunnyvale</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syracuse</th>\n",
       "      <td>Syracuse</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tacoma</th>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>1375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tampa</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tempe</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>825.0</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toledo</th>\n",
       "      <td>Toledo</td>\n",
       "      <td>OH</td>\n",
       "      <td>724.0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torrance</th>\n",
       "      <td>Torrance</td>\n",
       "      <td>CA</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>2695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Town of Madison</th>\n",
       "      <td>Town of Madison</td>\n",
       "      <td>WI</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>1645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trenton</th>\n",
       "      <td>Trenton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tucson</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tulsa</th>\n",
       "      <td>Tulsa</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vancouver</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>WA</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia Beach</th>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>VA</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Palm Beach</th>\n",
       "      <td>West Palm Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westhampton Beach</th>\n",
       "      <td>Westhampton Beach</td>\n",
       "      <td>NY</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>53900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weymouth</th>\n",
       "      <td>Weymouth</td>\n",
       "      <td>MA</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>1415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wichita</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>KS</td>\n",
       "      <td>550.0</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wynnewood</th>\n",
       "      <td>Wynnewood</td>\n",
       "      <td>PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Youngstown</th>\n",
       "      <td>Youngstown</td>\n",
       "      <td>OH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                City State  med_2011  med_2014\n",
       "City                                                          \n",
       "Akron                          Akron    OH     690.0     725.0\n",
       "Albany                        Albany    NY       NaN     952.0\n",
       "Albuquerque              Albuquerque    NM    1099.0    1150.0\n",
       "Alexandria                Alexandria    VA    2155.0    2250.0\n",
       "Amherst                      Amherst    MA       NaN       NaN\n",
       "Anaheim                      Anaheim    CA    2005.0    2245.0\n",
       "Anchorage                  Anchorage    AK       NaN    1995.0\n",
       "Arlington                  Arlington    VA    2800.0    2796.0\n",
       "Atlanta                      Atlanta    GA    2000.0    2450.0\n",
       "Auburn                        Auburn    WA    1045.0    1375.0\n",
       "Augusta                      Augusta    GA     826.0     955.0\n",
       "Aurora                        Aurora    CO    1350.0    1400.0\n",
       "Austin                        Austin    TX    1799.0    2800.0\n",
       "Bakersfield              Bakersfield    CA       NaN    1550.0\n",
       "Baltimore                  Baltimore    MD    2100.0    2210.0\n",
       "Beaverton                  Beaverton    OR     925.0    1167.0\n",
       "Bellevue                    Bellevue    WA    2290.0    2550.0\n",
       "Bellingham                Bellingham    WA     879.0     710.0\n",
       "Bend                            Bend    OR       NaN    1200.0\n",
       "Boise                          Boise    ID    1200.0     975.0\n",
       "Boston                        Boston    MA    3050.0    3500.0\n",
       "Boulder                      Boulder    CO    2500.0    2490.0\n",
       "Branford                    Branford    CT    1100.0     975.0\n",
       "Buffalo                      Buffalo    NY     625.0    1000.0\n",
       "Cambridge                  Cambridge    MA    2688.0    3000.0\n",
       "Chandler                    Chandler    AZ    1695.0    1900.0\n",
       "Charlotte                  Charlotte    NC    1500.0    1550.0\n",
       "Charlottesville      Charlottesville    VA     875.0    1195.0\n",
       "Chesapeake                Chesapeake    VA    1400.0    1950.0\n",
       "Chicago                      Chicago    IL    2095.0    2700.0\n",
       "...                              ...   ...       ...       ...\n",
       "Satellite Beach      Satellite Beach    FL     975.0    1050.0\n",
       "Scottsdale                Scottsdale    AZ    3000.0    3000.0\n",
       "Seattle                      Seattle    WA    2195.0    2450.0\n",
       "Shreveport                Shreveport    LA     815.0    1050.0\n",
       "South Bend                South Bend    IN       NaN     650.0\n",
       "Sparta                        Sparta    NJ    2200.0    2200.0\n",
       "Spokane                      Spokane    WA     660.0    1400.0\n",
       "Springfield              Springfield    MA     990.0    1100.0\n",
       "Stamford                    Stamford    CT    3900.0    4000.0\n",
       "Stockton                    Stockton    CA    1500.0    1500.0\n",
       "Sunnyvale                  Sunnyvale    CA       NaN    2750.0\n",
       "Syracuse                    Syracuse    NY       NaN     700.0\n",
       "Tacoma                        Tacoma    WA    1195.0    1375.0\n",
       "Tampa                          Tampa    FL    2029.0    2000.0\n",
       "Tempe                          Tempe    AZ     825.0    1195.0\n",
       "Toledo                        Toledo    OH     724.0     750.0\n",
       "Torrance                    Torrance    CA    1275.0    2695.0\n",
       "Town of Madison      Town of Madison    WI    1745.0    1645.0\n",
       "Trenton                      Trenton    NJ     900.0    1062.0\n",
       "Tucson                        Tucson    AZ    1050.0    1250.0\n",
       "Tulsa                          Tulsa    OK       NaN    1850.0\n",
       "Vancouver                  Vancouver    WA     720.0    1350.0\n",
       "Virginia Beach        Virginia Beach    VA    1725.0    1975.0\n",
       "Washington                Washington    DC    5000.0    3250.0\n",
       "West Palm Beach      West Palm Beach    FL    4000.0    3000.0\n",
       "Westhampton Beach  Westhampton Beach    NY   65000.0   53900.0\n",
       "Weymouth                    Weymouth    MA    1124.0    1415.0\n",
       "Wichita                      Wichita    KS     550.0     925.0\n",
       "Wynnewood                  Wynnewood    PA       NaN       NaN\n",
       "Youngstown                Youngstown    OH       NaN     500.0\n",
       "\n",
       "[175 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pandas_max_rent(df):\n",
    "    '''\n",
    "    INPUT: DataFrame\n",
    "    OUTPUT: DataFrame\n",
    "\n",
    "    Return a new pandas DataFrame which contains every city and the highest\n",
    "    median rent from that city for 2011 and 2014.\n",
    "\n",
    "    Note that city names are not unique and you need to use the state as well\n",
    "    so that Portland, ME and Portland, OR are recognized as different.\n",
    "\n",
    "    Your DataFrame should contain these columns:\n",
    "        City, State, med_2011, med_2014\n",
    "    '''\n",
    "    df_max_rent = (df[['City', 'State', 'med_2011', 'med_2014']]).groupby(['City']).max()\n",
    "    return df_max_rent\n",
    "\n",
    "pandas_max_rent(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T12:15:45.948942Z",
     "start_time": "2018-04-03T12:15:45.822247Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:57:20.441526Z",
     "start_time": "2018-04-03T10:57:20.358960Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_lists(list1, list2):\n",
    "    '''\n",
    "    INPUT: list, list\n",
    "    OUTPUT: list\n",
    "\n",
    "    list1 and list2 have the same length. Return a list which contains the\n",
    "    maximum element of each list for every index.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_diagonal(mat):\n",
    "    '''\n",
    "    INPUT: 2 dimensional list\n",
    "    OUTPUT: list\n",
    "\n",
    "    Given a matrix encoded as a 2 dimensional python list, return a list\n",
    "    containing all the values in the diagonal starting at the index 0, 0.\n",
    "\n",
    "    E.g.\n",
    "    mat = [[1, 2], [3, 4], [5, 6]]\n",
    "    | 1  2 |\n",
    "    | 3  4 |\n",
    "    | 5  6 |\n",
    "    get_diagonal(mat) => [1, 4]\n",
    "\n",
    "    You may assume that the matrix is nonempty.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def merge_dictionaries(d1, d2):\n",
    "    '''\n",
    "    INPUT: dictionary, dictionary\n",
    "    OUTPUT: dictionary\n",
    "\n",
    "    Return a new dictionary which contains all the keys from d1 and d2 with\n",
    "    their associated values. If a key is in both dictionaries, the value should\n",
    "    be the sum of the two values.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def make_char_dict(filename):\n",
    "    '''\n",
    "    INPUT: string\n",
    "    OUTPUT: dictionary (string => list)\n",
    "\n",
    "    Given a file containing rows of text, create a dictionary whose keys\n",
    "    are single characters. The value associated with each key is a list of all\n",
    "    the line numbers which start with that letter. The first line should have\n",
    "    line number 1.  Characters which never are the first letter of a line do\n",
    "    not need to be included in your dictionary.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "### Pandas\n",
    "# For each of these, you will be dealing with a DataFrame which contains median\n",
    "# rental prices in the US by neighborhood. The DataFrame will have these\n",
    "# columns:\n",
    "# Neighborhood, City, State, med_2011, med_2014\n",
    "\n",
    "def pandas_add_increase_column(df):\n",
    "    '''\n",
    "    INPUT: DataFrame\n",
    "    OUTPUT: None\n",
    "\n",
    "    Add a column to the DataFrame called 'Increase' which contains the\n",
    "    amount that the median rent increased by from 2011 to 2014.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def pandas_only_given_state(df, state):\n",
    "    '''\n",
    "    INPUT: DataFrame, string\n",
    "    OUTPUT: DataFrame\n",
    "\n",
    "    Return a new pandas DataFrame which contains the entries for the given\n",
    "    state. Only include these columns:\n",
    "        Neighborhood, City, med_2011, med_2014\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def pandas_max_rent(df):\n",
    "    '''\n",
    "    INPUT: DataFrame\n",
    "    OUTPUT: DataFrame\n",
    "\n",
    "    Return a new pandas DataFrame which contains every city and the highest\n",
    "    median rent from that city for 2011 and 2014.\n",
    "\n",
    "    Note that city names are not unique and you need to use the state as well\n",
    "    so that Portland, ME and Portland, OR are recognized as different.\n",
    "\n",
    "    Your DataFrame should contain these columns:\n",
    "        City, State, med_2011, med_2014\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "### SQL\n",
    "# For each of these, your python function should return a string that is the\n",
    "# SQL statement which answers the question.\n",
    "# For example:\n",
    "#    return '''SELECT * FROM rent;'''\n",
    "# You may want to run \"sqlite3 data/housing.sqlite\" in the command line to test\n",
    "# out your queries if the test is failing.\n",
    "#\n",
    "# There are two tables in the database with these columns:\n",
    "# (this is the same data that you dealt with in the pandas questions)\n",
    "#     rent: Neighborhood, City, State, med_2011, med_2014\n",
    "#     buy:  Neighborhood, City, State, med_2011, med_2014\n",
    "# The values in the date columns are integers corresponding to the price on\n",
    "# that date.\n",
    "\n",
    "def sql_count_neighborhoods():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: string\n",
    "\n",
    "    Return a SQL query that gives the number of neighborhoods in each city\n",
    "    according to the rent table. Keep in mind that city names are not always\n",
    "    unique unless you include the state as well, so your result should have\n",
    "    these columns (though you do not need to name them): city, state, cnt\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def sql_highest_rent_increase():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: string\n",
    "\n",
    "    Return a SQL query that gives the 5 San Francisco neighborhoods with the\n",
    "    highest rent increase.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def sql_rent_and_buy():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: string\n",
    "\n",
    "    Return a SQL query that gives the rent price and buying price for 2014 for\n",
    "    all the neighborhoods in San Francisco.\n",
    "    Your result should have these columns (though you do not need to name\n",
    "    them): neighborhood, rent, buy\n",
    "    '''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
