{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T18:09:25.627714Z",
     "start_time": "2018-04-10T18:09:25.621033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def roc_curve(probabilities, labels):\n",
    "    '''\n",
    "    INPUT: numpy array, numpy array\n",
    "    OUTPUT: list, list, list\n",
    "\n",
    "    Take a numpy array of the predicted probabilities and a numpy array of the\n",
    "    true labels.\n",
    "    Return the True Positive Rates, False Positive Rates and Thresholds for the\n",
    "    ROC curve.\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# grad.csv\n",
    "# loanf.csv\n",
    "# mooc.csv\n",
    "# mooc.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T18:10:42.234725Z",
     "start_time": "2018-04-10T18:10:42.223269Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T18:10:52.192027Z",
     "start_time": "2018-04-10T18:10:52.184675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01894774, -0.85308133],\n",
       "       [ 1.54682739,  1.55495138],\n",
       "       [-1.05312626,  1.12429009],\n",
       "       ...,\n",
       "       [-0.36426766, -0.77428745],\n",
       "       [-2.15761295,  2.04414266],\n",
       "       [-0.84465687, -0.89877712]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if you're instantiating, how would it affect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T18:10:46.543679Z",
     "start_time": "2018-04-10T18:10:46.530659Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9b44662045aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"False Positive Rate (1 - Specificity)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True Positive Rate (Sensitivity, Recall)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ROC Curve \n",
    "\n",
    "One of the best ways to evaluate how a classifier performs is an ROC curve. (http://en.wikipedia.org/wiki/Receiver_operating_characteristic) \n",
    "\n",
    "![](images/roc_curve.png)\n",
    "\n",
    "To understand what is actually happening with an ROC curve, we can create one ourselves.  Here is pseudocode to plot it.\n",
    "\n",
    "The `probabilities` are values in (0,1) returned from Logistic Regression. The standard default threshold is 0.5 where \n",
    "0-0.5 values are interpreted as the negative class and 0.5-1 values are predicted as the positive class.\n",
    "\n",
    "The `labels` are the true values.\n",
    "\n",
    "```\n",
    "function ROC_curve(probabilities, labels):\n",
    "    Sort instances by their prediction strength (the probabilities)\n",
    "    For every instance in increasing order of probability:\n",
    "        Set the threshold to be the probability\n",
    "        Set everything above the threshold to the positive class\n",
    "        Calculate the True Positive Rate (aka sensitivity or recall)\n",
    "        Calculate the False Positive Rate (1 - specificity)\n",
    "    Return three lists: TPRs, FPRs, thresholds\n",
    "```\n",
    "\n",
    "Recall that the *true positive rate* is\n",
    "\n",
    "```\n",
    " number of true positives     number correctly predicted positive\n",
    "-------------------------- = -------------------------------------\n",
    " number of positive cases           number of positive cases\n",
    "```\n",
    "\n",
    "and the *false positive rate* is\n",
    "\n",
    "```\n",
    " number of false positives     number incorrectly predicted positive\n",
    "--------------------------- = ---------------------------------------\n",
    "  number of negative cases           number of negative cases\n",
    "```\n",
    "\n",
    "You're going to be implementing the `roc_curve` function.\n",
    "\n",
    "Here's some example code that you should be able to use to plot the ROC curve with your function. This uses a fake dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "1. Write an ROC curve function to compute the above in `roc_curve.py`.\n",
    "\n",
    "    It should take as input the predicted probabilities and the true labels.\n",
    "\n",
    "2. Run the above code to verify that it's working correctly. You can also validate your correctness against [scikit-learns built-in function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html).\n",
    "\n",
    "3. Let's see how the roc curve looks on a real dataset. We're going to use the FICO Loan dataset. We want to predict whether or not you get approved for a loan of 12% interest rate given the FICO Score, Loan Length and Loan Amount. Here's the code to load the data:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/loanf.csv')\n",
    "    y = (df['Interest.Rate'] <= 12).values\n",
    "    X = df[['FICO.Score', 'Loan.Length', 'Loan.Amount']].values\n",
    "    ```\n",
    "\n",
    "    Make sure to split your data into training and testing using sklearn's [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html).\n",
    "\n",
    "## Part 2: Data Exploration: Graduate School Admissions\n",
    "\n",
    "The data we will be using is admission data on Grad school acceptances.\n",
    "\n",
    "* `admit`: whether or not the applicant was admitted to grad. school\n",
    "* `gpa`: undergraduate GPA\n",
    "* `gre`: score of GRE test\n",
    "* `rank`: prestige of undergraduate school (1 is highest prestige, ala Harvard)\n",
    "\n",
    "We will use the GPA, GRE, and rank of the applicants to try to predict whether or not they will be accepted into graduate school.\n",
    "\n",
    "Before we get to predictions, we should do some data exploration.\n",
    "\n",
    "1. Load in the dataset into pandas: `data/grad.csv`.\n",
    "\n",
    "2. Use the pandas `describe` method to get some preliminary summary statistics on the data. In particular look at the mean values of the features.\n",
    "\n",
    "3. Use the pandas `crosstab` method to see how many applicants from each rank of school were accepted. You should get a dataframe that looks like this:\n",
    "\n",
    "    ```\n",
    "    rank    1   2   3   4\n",
    "    admit\n",
    "    0      28  ..  ..  ..\n",
    "    1      33  ..  ..  ..\n",
    "    ```\n",
    "\n",
    "    Make a bar plot of the percent of applicants from each rank who were accepted. You can do `.plot(kind=\"bar\")` on a pandas dataframe.\n",
    "\n",
    "4. What does the distribution of the GPA and GRE scores look like? Do the distributions differ much?\n",
    "\n",
    "    Hint: Use the pandas `hist` method.\n",
    "\n",
    "5. One of the issues with classification can be unbalanced classes. What percentage of the data was admitted? Do you think this will be a problem?\n",
    "\n",
    "\n",
    "## Part 3: Predicting Graduate School Admissions\n",
    "\n",
    "Now we're ready to try to fit our data with Logistic Regression.\n",
    "\n",
    "We're going to start with statsmodel's implementation of [Logistic Regression](http://statsmodels.sourceforge.net/stable/generated/statsmodels.discrete.discrete_model.Logit.html) and then move onto sklearn's [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "1. Use statsmodels to fit a [Logistic Regression](http://statsmodels.sourceforge.net/stable/generated/statsmodels.discrete.discrete_model.Logit.html).\n",
    "\n",
    "2. Use the `summary` method to see your results. Look at the p-values for the beta coefficients. We would like these to be significant. Are they?\n",
    "\n",
    "3. Once we feel comfortable with our model, we can move on to cross validation. We no longer will need all the output of statsmodels so we can switch to sklearn. Use sklearn's [KFold cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) and [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to calculate the average accuracy, precision and recall.\n",
    "\n",
    "    Hint: Use sklearn's implementation of these scores in [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "4. The `rank` column is ordinal where we assume an equal change between ranking levels, but we could also consider it to be more generally categorical. Use panda's [get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.reshape.get_dummies.html) to binarize the column.\n",
    "\n",
    "5. Compute the same metrics as above. Does it do better or worse with the rank column binarized?\n",
    "\n",
    "    From now on, use the version of the feature matrix that performed the best.\n",
    "\n",
    "6. Make a plot of the ROC curve (using your function defined in Part 1).\n",
    "\n",
    "7. Is it possible to pick a threshold where TPR > 60% and FPR < 40%? What is the threshold?\n",
    "\n",
    "    *Note that even if it appears to be in the middle of the graph it doesn't make the threshold 0.5.*\n",
    "\n",
    "8. Say we are using this as a first step in the application process. We want to weed out clearly unqualified candidates, but not reject too many candidates. What might be a good choice of threshold?\n",
    "\n",
    "    There isn't a single correct answer, so explain your choice!\n",
    "\n",
    "\n",
    "## Part 4: Interpreting the beta coefficients with the Odds Ratio\n",
    "\n",
    "One thing that is often lost when talking about logistic regression is the idea of the odds ratio, or rather the probabilistic interpretation of the model. For this next part we will get hands on with the odds ratio.\n",
    "\n",
    "The ***odds*** are defined as the product of the exponential of each coefficient.\n",
    "\n",
    "![](images/odds.gif)\n",
    "\n",
    "This represents the odds of being admitted over not being admitted.\n",
    "\n",
    "However, to bring the logistic regression function into the form that resembles a linear predictor, we focus on the logit function known as the logodds.\n",
    "\n",
    "![](images/logodds.gif)\n",
    "\n",
    "Note: The base chosen in statistics for the logarithm is traditionally `base e` and the natural logarithm used.\n",
    "\n",
    "With this transformation, the coefficients of the logistic regression can be interpreted similarly to the coefficients of linear regression; however, they correspond to the change in logodds, which does not have an intuitive meaning.  Luckily, we can calculate the Odds Ratio by exponentiating the beta coefficients\n",
    "\n",
    " ![](images/odds_ratio.gif)\n",
    "\n",
    "The Odds Ratio represents the relative change in odds due to a 1-unit change in the feature.  For instance, the odds that Secratariat will win the Kentucky Derby are 3 times greater when its a dry track than if its been raining.\n",
    "\n",
    "\n",
    "1. Fit a Logistic Regression model on all the data. What are the beta coefficients? You should have 3 values.\n",
    "\n",
    "2. Compute the odds ratio from a one unit change in each feature. \n",
    "\n",
    "3. Write a sentence for each of the three features that sounds like this:\n",
    "\n",
    "    *Increasing the GPA by 1 point increases the odds by a factor of ??.*\n",
    "\n",
    "    Make sure you think about each statement. Does it make sense?\n",
    "\n",
    "4. What change is required to double my chances of admission? Treat each of the features individually.\n",
    "\n",
    "    e.g. Increasing the GPA by ?? points doubles the odds.\n",
    "\n",
    "    *Hint: You need to find the value of k in the following equation.*\n",
    "\n",
    "    ![](images/odds_double.gif)\n",
    "\n",
    "\n",
    "## Part 5: Predicted Probabilities\n",
    "\n",
    "Now let's actually play with our data to verify what we calculated above with the Odds Ratio.\n",
    "\n",
    "1. Create a new feature matrix which has four rows. It should have each of the four possible values for the rank and keep the GRE and GPA values fixed. Use the mean value as a reasonable value to fix them at.\n",
    "\n",
    "2. Use the same fitted model from Part 4 and then use the model's `predict_proba` method to compute the predicted probabilities of this fake feature matrix. Also include the odds (`p/(1-p)`).\n",
    "\n",
    "    Note that it gives a numpy array with 2 columns. The first column is the probability that it belongs to class 0 and the second is the probability that it belongs to class 1. These will always sum to 1, so with 2 classes, this is redundant. In this case, the second column is the one we should use since it has the probabilities we expect.\n",
    "\n",
    "    You should end up with something like this:\n",
    "\n",
    "    ```\n",
    "    rank: 1, probability: 0.517495, odds: 1.07251738\n",
    "    ```\n",
    "\n",
    "    Does the ratio of odds equal what you computed above?\n",
    "\n",
    "3. Make a plot of the rank vs the probability.\n",
    "\n",
    "4. Now, make a plot of the rank vs the odds (`p/(1-p)`).\n",
    "\n",
    "5. Since a linear change in rank changes the probability by a multiplicative factor, we should really be graphing rank vs the log-odds.\n",
    "\n",
    "    The slope of this line should be the beta coefficient. Eyeball calculating the slope to confirm this.\n",
    "\n",
    "6. Do the same analysis (#1-5) with the GRE and GPA scores. Each time, create a feature matrix with the other two columns fixed at the mean and every possible value of the column in question.\n",
    "\n",
    "## Extra credit\n",
    "\n",
    "This is the future!  No one goes to physical schools any more and MOOCs rule the world.\n",
    "\n",
    "Harvard and MIT have [released](http://newsoffice.mit.edu/2014/mit-and-harvard-release-de-identified-learning-data-open-online-courses) a great dataset around engagement statistics for their MOOC courses. The data is in `data/mooc.csv` and a description of the dataset can be found in `data/mooc.pdf`.\n",
    "\n",
    "One of the biggest issues with MOOCs is engagement. We will try to predict the probability of 'engagement' of a student given all the other columns.  We will define engagement here as either: `explored == 1 OR certified == 1`.\n",
    "\n",
    "1. First explore all of the classes, what are the rates of certified and explored for each.  Which one has the highest percent of each?  How about for engagement as defined above?\n",
    "\n",
    "2. Build a column labeled 'engagement' that represents this definition.\n",
    "\n",
    "3. Try to predict the engagement of a student.  Remember we do not want to use any columns that we will not have before a student has completed a course in a live scenario (i. e. `grade`, `viewed`, `explored`, `certified`, etc.)\n",
    "\n",
    "4. Plot a confusion matrix and an ROC curve to evaluate your model\n",
    "\n",
    "5. Which of these features is most important for engagement?\n",
    "\n",
    "6. How does recall compare to precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
