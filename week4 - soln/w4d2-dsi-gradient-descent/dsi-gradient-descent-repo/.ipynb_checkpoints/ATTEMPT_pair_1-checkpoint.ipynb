{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:06:58.297898Z",
     "start_time": "2018-04-05T22:06:56.499137Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# COLLAPSE CELL\n",
    "# PMsearch np.v*\n",
    "#x = data['mass']\n",
    "#x?\n",
    "\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='solarized')\n",
    "# from jupyterlab_table import JSONTable\n",
    "# JSONTable(df)\n",
    "\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pprint import pprint\n",
    "import math\n",
    "import statsmodels.stats as sms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.regression as smr\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# 04atplotlib inline\n",
    "# %load_ext heat\n",
    "\n",
    "plt.ion()\n",
    "# plt.ioff()\n",
    "\n",
    "# %heat\n",
    "\n",
    "import os \n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "We will be implementing logistic regression using the gradient descent algorithm.\n",
    "\n",
    "#### References:\n",
    "* [Andrew Ng's Machine Learning Lecture Notes](https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf)\n",
    "\n",
    "#### Notes on Implementing Gradient Descent:\n",
    "* Implementing gradient descent can lead to challenging debugging. Make sure you implement your algorithm using very simple pieces (functions or methods) which you then combine into the full algorithm.  This allows you to check the correctness of the individual functions, which makes mistakes easier to track down. You may also try computing values by hand for a really simple example (1 feature, 2 data points) and make sure that your methods are getting the same values.\n",
    "* Numpy is your friend. Use the power of it! There should only be one loop in\n",
    "your code (in `fit`). You should never have to loop over a numpy array. See the\n",
    "numpy [tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html) and\n",
    "[documentation](http://docs.scipy.org/doc/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:06:58.379620Z",
     "start_time": "2018-04-05T22:06:58.328781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:06:58.727122Z",
     "start_time": "2018-04-05T22:06:58.719455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100,\n",
    "                            n_features=2,\n",
    "                            n_informative=2,\n",
    "                            n_redundant=0,\n",
    "                            n_classes=2,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T21:56:31.204793Z",
     "start_time": "2018-04-05T21:56:31.189714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:06:59.804848Z",
     "start_time": "2018-04-05T22:06:59.796917Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_X(X, y):\n",
    "    # https://stackoverflow.com/questions/4455076/how-to-access-the-ith-column-of-a-numpy-multidimensional-array\n",
    "    # X[0]\n",
    "    colors = np.array([\"red\", \"blue\"])[y]\n",
    "    x1 = X[:,0]\n",
    "    x2 = X[:,1]\n",
    "    plt.scatter(x1,x2, color=colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:07:00.496780Z",
     "start_time": "2018-04-05T22:07:00.284440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8s02JC3IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114077358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_X(X,y)\n",
    "# (-3,-3)(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T21:47:58.193102Z",
     "start_time": "2018-04-05T21:47:57.971434Z"
    }
   },
   "source": [
    "## Part 2: Cost function\n",
    "\n",
    "In order to be able to evaluate if our gradient descent algorithm is working\n",
    "correctly, we will need to be able to calculate the cost.\n",
    "\n",
    "Recall the log likelihood function for logistic regression. Our goal is to *maximize* this value.\n",
    "\n",
    "![Cost Function](images/likelihood.png)\n",
    "<!--\n",
    "\\ell(\\boldsymbol\\beta) = \\sum_{i=1}^{n} y_i \\log ( h(\\mathbf{x_i}) ) + (1-y_i) \\log (1 - h(\\mathbf{x_i}))\n",
    "-->\n",
    "\n",
    "Recall that the hypothesis function *h* is defined as follows:\n",
    "#### NOTE: Image = not perfect. Exponent should be (sum_j=0_to_m of B_j * X_ij). In other words, matrix mult the coeff and X\n",
    "![hypothesis](images/hypothesis.png)\n",
    "<!--\n",
    "h(\\mathbf{x_i}) = \\frac{1}{1+e^{-\\boldsymbol\\beta\\mathbf{x_i}}}\n",
    "-->\n",
    "\n",
    "Since we will be implemented Gradient *Descent*, which *minimizes* a function, we'll look at the cost function below, which is just the negation of the log likelihood function above.\n",
    "\n",
    "![cost function](images/cost.png)\n",
    "<!--\n",
    "J(\\boldsymbol\\beta) = - \\sum_{i=1}^{n} y_i \\log ( h(\\mathbf{x_i}) ) + (1-y_i) \\log (1 - h(\\mathbf{x_i}))\n",
    "-->\n",
    "\n",
    "The gradient of the cost function is as follows:\n",
    "![gradient](images/gradient.png)\n",
    "<!--\n",
    "\\nabla J(\\boldsymbol\\beta) =\n",
    "\\left[\n",
    "\\frac\\partial{\\partial\\beta_1}J(\\boldsymbol\\beta),\n",
    "\\frac\\partial{\\partial\\beta_2}J(\\boldsymbol\\beta),\n",
    "\\ldots,\n",
    "\\frac\\partial{\\partial\\beta_p}J(\\boldsymbol\\beta)\n",
    "\\right]\n",
    "-->\n",
    "\n",
    "Each partial derivative will be computed as follows:\n",
    "\n",
    "![partial](images/partial.png)\n",
    "<!--\n",
    "\\frac\\partial{\\partial\\beta_j}J(\\boldsymbol\\beta) =\n",
    "\\sum_{i=1}^n \\left( h(\\mathbf{x_i}) - y_i \\right ) x_{ij}\n",
    "-->\n",
    "\n",
    "1. To verify that your implementations are correct, compute the following _by hand_. Of course, you can use a calculator/google/wolfram alpha/python.\n",
    "\n",
    "|        Order       | feature 1 | feature 2 |   y |\n",
    "| ----------------- | --------: | --------: | --: |\n",
    "| **x<sub>1</sub>** |         0 |         1 |   1 |\n",
    "| **x<sub>2</sub>** |         2 |         2 |   0 |\n",
    "| **x<sub>3</sub>** |         3 |         0 |   0 |\n",
    "\n",
    "    1. Using the data above, compute the **value of the cost function**. Initialize your coefficients:\n",
    "    β<sub>1</sub> =1, β<sub>2</sub> =1.\n",
    "    \n",
    "        Hint: you will use\n",
    "        (β<sub>1</sub>x<sub>1,1</sub> + β<sub>2</sub>x<sub>1,2</sub>)\n",
    "        while computing your hypothesis function for the first data point.\n",
    "    \n",
    "    2. Using the data above, compute the **gradient of the cost function**.\n",
    "    \n",
    "\n",
    "2. In `logistic_regression_functions.py`, implement `predict_proba` and `predict` functions. `predict_proba` will calculate the result of `h(x)` for the given coefficients. This returns float values between 0 and 1, which should be interpreted as conditional probabilities. `predict` will round these values so that you get a prediction of either 0 or 1. An optional argument is provided for the threshold, which is defaulted to `0.5`.  **Note:** The names of these functions were chosen to align with `sklearn`'s conventions.\n",
    "\n",
    "3. In `logistic_regression_functions.py`, implement `cost` and `gradient`. You should be able to use the `predict_proba` function you implemented above. Make sure to check that you get the same values as you computed above.\n",
    "\n",
    "    In a terminal, you should be able to run your function like this:\n",
    "\n",
    "    ```python\n",
    "    import logistic_regression_functions as f\n",
    "    import numpy as np\n",
    "    X = np.array([[0, 1], [2, 2], [3, 0]])\n",
    "    y = np.array([1, 0, 0])\n",
    "    coeffs = np.array([1, 1])\n",
    "    f.cost(X, y, coeffs)\n",
    "    ```\n",
    "\n",
    "    Make sure to do `reload(f)` if you make changes to your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:09:26.854848Z",
     "start_time": "2018-04-05T22:09:26.848028Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    |                   | feature 1 | feature 2 |   y |\\n    | ----------------- | --------: | --------: | --: |\\n    | **x<sub>1</sub>** |         0 |         1 |   1 |\\n    | **x<sub>2</sub>** |         2 |         2 |   0 |\\n    | **x<sub>3</sub>** |         3 |         0 |   0 |\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    |                   | feature 1 | feature 2 |   y |\n",
    "    | ----------------- | --------: | --------: | --: |\n",
    "    | **x<sub>1</sub>** |         0 |         1 |   1 |\n",
    "    | **x<sub>2</sub>** |         2 |         2 |   0 |\n",
    "    | **x<sub>3</sub>** |         3 |         0 |   0 |\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T22:17:57.927160Z",
     "start_time": "2018-04-05T22:17:57.469453Z"
    }
   },
   "outputs": [],
   "source": [
    "# import logistic_regression_functions as lrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T23:10:56.450658Z",
     "start_time": "2018-04-05T23:10:56.346330Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_proba(X, coeffs):\n",
    "    \"\"\"Calculate the predicted conditional probabilities (floats between 0 and\n",
    "    1) for the given data with the given coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2 dimensional numpy array.  The data (independent variables) to use\n",
    "        for prediction.\n",
    "    coeffs: A 1 dimensional numpy array, the hypothesized coefficients.  Note\n",
    "        that the shape of X and coeffs must align.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_probabilities: The conditional probabilities from the logistic\n",
    "        hypothesis function given the data and coefficients.\n",
    "\n",
    "    \"\"\"\n",
    "    linear_predictor = np.dot(X, coeffs)\n",
    "    denom = 1 + np.exp(-linear_predictor)\n",
    "    return 1 / denom\n",
    "\n",
    "\n",
    "def predict(X, coeffs, thresh=0.5):\n",
    "    \"\"\"\n",
    "    Calculate the predicted class labels (0 or 1) for the given data with the\n",
    "    given coefficients by comparing the predicted probabilities to a given\n",
    "    threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2 dimensional numpy array.  The data (independent variables) to use\n",
    "        for prediction.\n",
    "    coeffs: A 1 dimensional numpy array, the hypothesized coefficients.  Note\n",
    "        that the shape of X and coeffs must align.\n",
    "    thresh: Threshold for comparison of probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted_class: The predicted class.\n",
    "    \"\"\"\n",
    "    probs = predict_proba(X, coeffs)\n",
    "    return probs >= thresh\n",
    "\n",
    "\n",
    "def cost(X, y, coeffs, lam=0.0, has_intercept=True):\n",
    "    \"\"\"\n",
    "    Calculate the logistic cost function of the data with the given\n",
    "    coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2 dimensional numpy array.  The data (independent variables) to use\n",
    "        for prediction.\n",
    "    y: A 1 dimensional numpy array.  The actual class values of the response.\n",
    "        Must be encoded as 0's and 1's.  Also, must align properly with X and\n",
    "        coeffs.\n",
    "    coeffs: A 1 dimensional numpy array, the hypothesized coefficients.  Note\n",
    "        that the shape of X, y, and coeffs must align.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logistic_cost: The computed logistic cost.\n",
    "    \"\"\"\n",
    "    p = predict_proba(X, coeffs)\n",
    "    cost_per_observation = y * np.log(p) + (1 - y) * np.log(1 - p)\n",
    "    ridge_penalty = np.sum(coeffs*coeffs)\n",
    "    if has_intercept:\n",
    "        ridge_penalty -= coeffs[0]*coeffs[0]\n",
    "    return -np.sum(cost_per_observation) + lam * ridge_penalty\n",
    "\n",
    "def cost_one_datapoint(x, y, coeffs):\n",
    "    \"\"\"\n",
    "    Calculate the logistic cost function of a single data point using the given\n",
    "    coefficients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray, shape (n_features, )\n",
    "        The data (independent variables) to use for prediction.\n",
    "    y: Integer, 0 or 1 \n",
    "        The actual class values of the response.\n",
    "    coeffs: ndarray, shape (n_features)\n",
    "        The hypothosized coefficients of the logistic regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logistic_cost: float\n",
    "        The computed logistic cost.\n",
    "    \"\"\"\n",
    "    linear_pred = np.sum(x * coeffs)\n",
    "    p = 1 / (1 + np.exp(-linear_pred))\n",
    "    return (- y * np.log(p) - (1 - y) * np.log(1 - p))\n",
    "\n",
    "\n",
    "def gradient(X, y, coeffs, lam=0.0, has_intercept=True):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the logistic cost function at the given value for\n",
    "    the coeffs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray, shape (n_samples, n_features)\n",
    "        The data (independent variables) to use for prediction.\n",
    "    y: ndarray, shape (n_samples, )\n",
    "        The actual class values of the response.  Must be encoded as 0's and\n",
    "        1's.\n",
    "    coeffs: ndarray, shape (n_features)\n",
    "        The hypothosized coefficients of the logistic regression.\n",
    "    lam: float \n",
    "        Strength of regularization parameter for the ridge penalty.\n",
    "    has_intercept: boolean \n",
    "        Is the first entry of coeffs an intercept parameter?\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logistic_grad: ndarray, shape (n_features, )\n",
    "        The computed gradient of the logistic cost.\n",
    "    \"\"\"\n",
    "    p = predict_proba(X, coeffs)\n",
    "    ridge_grad = 2 * coeffs\n",
    "    if has_intercept:\n",
    "        ridge_grad[0] = 0.0\n",
    "    return np.dot(X.T, p - y) + lam * ridge_grad\n",
    "\n",
    "\n",
    "def gradient_one_datapoint(x, y, coeffs):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the logistic cost function evaluated at a single\n",
    "    data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: ndarray, shape (n_features, )\n",
    "        The data (independent variables) to use for prediction.\n",
    "    y: Integer, 0 or 1 \n",
    "        The actual class values of the response.\n",
    "    coeffs: ndarray, shape (n_features)\n",
    "        The hypothosized coefficients of the logistic regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logistic_grad: ndarray, shape (n_features, )\n",
    "        The computed gradient of the logistic cost.\n",
    "    \"\"\"\n",
    "    linear_pred = np.sum(x * coeffs)\n",
    "    p = 1 / (1 + np.exp(-linear_pred))\n",
    "    return (x * (p - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T23:13:37.504820Z",
     "start_time": "2018-04-05T23:13:37.498627Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0, 1], [2, 2], [3, 0]])\n",
    "x = np.array([1])\n",
    "y = np.array([1, 0, 0])\n",
    "coeffs = np.array([1, -0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T23:03:38.836661Z",
     "start_time": "2018-04-05T23:03:38.831264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cost function](images/cost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T23:55:14.034361Z",
     "start_time": "2018-04-05T23:55:13.912753Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-a28d2aa8603c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "p = predict_proba(X, coeffs)\n",
    "y_hat = predict(X, coeffs)\n",
    "cost = cost(X, y, coeffs)\n",
    "grad = gradient(X, y, coeffs)\n",
    "\n",
    "print(\"The predicted probability vector is {}\".format(str(p)))\n",
    "print(\"The predicted class vector is {}\".format(str(y_hat)))\n",
    "print(\"The cost function at these coefficients is {}\".format(str(cost)))\n",
    "print(\"The gradient of the cost is {}\".format(str(grad)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T23:44:26.742167Z",
     "start_time": "2018-04-05T23:44:26.716198Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class GradientDescent(object):\n",
    "    \"\"\"Perform the gradient descent optimization algorithm for an arbitrary\n",
    "    cost function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cost, gradient, predict_func, \n",
    "                 alpha=0.01,\n",
    "                 num_iterations=10000):\n",
    "        \"\"\"Initialize the instance attributes of a GradientDescent object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cost: The cost function to be minimized.\n",
    "        gradient: The gradient of the cost function.\n",
    "        predict_func: A function to make predictions after the optimization has\n",
    "            converged.\n",
    "        alpha: The learning rate.\n",
    "        num_iterations: Number of iterations to use in the descent.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: The initialized GradientDescent object.\n",
    "        \"\"\"\n",
    "        # Initialize coefficients in run method once you know how many features\n",
    "        # you have.\n",
    "        self.coeffs = None\n",
    "        self.cost = cost\n",
    "        self.gradient = gradient\n",
    "        self.predict_func = predict_func\n",
    "        self.alpha = alpha\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Run the gradient descent algorithm for num_iterations repetitions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: A two dimenstional numpy array.  The training data for the\n",
    "            optimization.\n",
    "        y: A one dimenstional numpy array.  The training response for the\n",
    "            optimization.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self:  The fit GradientDescent object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Call self.predict_func to return predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: Data to make predictions on.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preds: A one dimensional numpy array of predictions.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gd = GradientDescent(cost, gradient, predict)\n",
    "gd.fit(X, y)\n",
    "print(\"coeffs:\", gd.coeffs)\n",
    "predictions = gd.predict(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
