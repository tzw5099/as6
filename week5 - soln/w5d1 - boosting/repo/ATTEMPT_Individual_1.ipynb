{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T15:41:44.174941Z",
     "start_time": "2018-04-09T15:41:42.228303Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# COLLAPSE CELL\n",
    "# AMsearch np.v*\n",
    "#x = data['mass']\n",
    "#x?\n",
    "\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='solarized')\n",
    "# from jupyterlab_table import JSONTable\n",
    "# JSONTable(df)\n",
    "\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# from notebook.services.config import ConfigManager\n",
    "# cm = ConfigManager().update('notebook', {'limit_output': 1000})\n",
    "\n",
    "import better_exceptions\n",
    "better_exceptions.MAX_LENGTH = None\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pprint import pprint\n",
    "import math\n",
    "import statsmodels.stats as sms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.regression as smr\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# 04atplotlib inline\n",
    "# %load_ext heat\n",
    "\n",
    "plt.ion()\n",
    "# plt.ioff()\n",
    "\n",
    "# %heat\n",
    "\n",
    "import os \n",
    "# dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T15:43:27.991472Z",
     "start_time": "2018-04-09T15:43:27.936188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T17:36:27.950618Z",
     "start_time": "2018-04-09T17:36:27.935065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "# House Prices\n",
    "y = boston.target\n",
    "# The other 13 features\n",
    "x = boston.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a train_test_split where train : test is 80 : 20. Set\n",
    "random_state=1 so the exact same split can be replicated later.\n",
    "All subsequent model selection will be carried out with the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T01:38:38.496706Z",
     "start_time": "2018-04-10T01:38:38.488209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = .2, random_state = 1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in comparing 3 classes of ML algorithms here:\n",
    "\n",
    "- RandomForestRegressor\n",
    "- AdaBoostRegressor\n",
    "- GradientBoostingRegressor\n",
    "Boosted decision trees (AdaBoost, GradientBoosting & others)\n",
    "have been shown empirically to outperform RandomForest on average\n",
    "(Table 4 - R. Caruana et. al.) in terms\n",
    "of predictive power. The runtime for boosting algorithms, as you will\n",
    "experience, is also competitive with random forest.\n",
    "\n",
    "As a starting point, below are instantiations of the 3 classes of\n",
    "algorithms. I have given you a set of hyperparameters for each\n",
    "class. Do not worry about tuning the parameters for now, we will do a\n",
    "GridSearch at the end of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T17:36:32.342026Z",
     "start_time": "2018-04-09T17:36:32.334787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=1)\n",
    "\n",
    "gdbr = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                  loss='ls',\n",
    "                                  n_estimators=100,\n",
    "                                  random_state=1)\n",
    "\n",
    "abr = AdaBoostRegressor(DecisionTreeRegressor(),\n",
    "                         learning_rate=0.1,\n",
    "                         loss='linear',\n",
    "                         n_estimators=100,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Using `cross_val_score` in `sklearn`, define a function that \n",
    "   calculates the cross-validated train MSE and R2 for `AdaBoostRegressor`,\n",
    "   `GradientBoostingRegressor`, `RandomForestRegressor`.\n",
    "\n",
    "   **Your output should be similar to this (Do not worry if the numbers do\n",
    "   not match up exactly):**\n",
    "\n",
    "   ```\n",
    "   RandomForestRegressor     Train CV | MSE: 9.865 | R2: 0.867\n",
    "   GradientBoostingRegressor Train CV | MSE: 8.533 | R2: 0.885\n",
    "   AdaBoostRegressor         Train CV | MSE: 9.663 | R2: 0.870\n",
    "   ```\n",
    "\n",
    "   Which of the models cross validates the best? Why is it inappropriate\n",
    "   to make a judgement on the performance of the models\n",
    "   based only on the evidence we have thus far?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T01:39:48.970228Z",
     "start_time": "2018-04-10T01:39:47.686818Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/tomwong/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-10.320121093569186, 0.8691052879724385)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf\n",
    "# gdbr\n",
    "# abr\n",
    "\n",
    "k = 10\n",
    "def cross_val(estimator, X_train, X_test, y_train, y_test, nfolds):\n",
    "#     rf_fit = rf.fit(X_train,y_train)\n",
    "#     gdbr_fit = gdbr.fit(X_train,y_train)\n",
    "#     abr_fit = abr.fit(X_train,y_train)\n",
    "\n",
    "    rf_y_hat_train_predicted = rf.predict(X_train)\n",
    "\n",
    "    rf_score_mse = cross_val_score(rf, X_train, y_train, scoring='mean_squared_error', n_jobs=-1).mean()\n",
    "\n",
    "    # rf_score_mse = cross_val_score(rf, x,y, scoring='mean_squared_error').mean()\n",
    "    rf_score_r2 = cross_val_score(rf, X_train, y_train, scoring='r2', n_jobs=-1).mean()\n",
    "\n",
    "#     rf_score_mse\n",
    "#     rf_score_r2\n",
    "    return rf_score_mse, rf_score_r2\n",
    "\n",
    "cross_val(rf, X_train, X_test, y_train, y_test, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. Define a new instance of `GradientBoostingRegressor` with the exact same\n",
    "   hyperparameters as above, except change the `learning_rate` to `1`\n",
    "   (instead of `0.1`). Calculate the cross-validated train MSE.\n",
    "    What do you notice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) We're going to make a plot to help us understand the impact of the learning rate\n",
    "   and the improvements in error after each iteration of the boosting.\n",
    "   \n",
    "   [`staged_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor.staged_predict) is a method in both\n",
    "   `GradientBoostingRegressor` and `AdaBoostRegressor`. It allows us to get\n",
    "   predictions from the estimator after each iteration of the boosting.\n",
    "   \n",
    "   Using\n",
    "   `stage_predict`, define a function `stage_score_plot` that calculates the test and train\n",
    "   MSE from each estimator. Do the calculations for `GradientBoostingRegressor`\n",
    "   with `learning_rate=1` and `learning_rate=0.1`\n",
    "   \n",
    "   And get a result which looks like this:\n",
    "\n",
    "   ![stage_score_plot](images/stage_score_plot.png)\n",
    "   \n",
    "   In order to get the labels for the plot, you can use `model.__class__.__name__` to get the model name and `model.learning_rate` to get the learning rate.\n",
    "\n",
    "\n",
    "7) Use your `stage_score_plot` function to make a plot that shows the error\n",
    "   for gradient boosting with a learning rate of 0.1 and 1.\n",
    "\n",
    "   Since you are comparing two models and we're showing both the training and\n",
    "   test error, you should have 4 lines on your graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T17:26:27.634411Z",
     "start_time": "2018-04-09T17:26:27.624734Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T17:26:27.928053Z",
     "start_time": "2018-04-09T17:26:27.905643Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected sequence object with len >= 0 or a single integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d9a46e558946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   random_state=1)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_optimal_n_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-bd79b37382c1>\u001b[0m in \u001b[0;36mget_optimal_n_estimators\u001b[0;34m(model, X_new, y_new)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_optimal_n_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         validation_loss = np.zeros(\n\u001b[0;32m----> 3\u001b[0;31m         model.get_params('n_estimators'))\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected sequence object with len >= 0 or a single integer"
     ]
    }
   ],
   "source": [
    "# not working - get_optimal_n_estimators\n",
    "def get_optimal_n_estimators(model, X_new, y_new):\n",
    "        validation_loss = np.zeros(\n",
    "        model.get_params('n_estimators'))\n",
    "        for i, preds in enumerate(model.staged_predict(X_new)):\n",
    "            validation_loss[i] = model.loss_(preds, y_new)\n",
    "        optimal_tree = np.argmin(validation_loss)\n",
    "        optimal_loss = validation_loss[optimal_tree]\n",
    "        return optimal_tree, optimal_loss\n",
    "    \n",
    "gdbr = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                  loss='ls',\n",
    "                                  n_estimators = 100,\n",
    "                                  random_state=1)\n",
    "get_optimal_n_estimators(gdbr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T19:09:42.678629Z",
     "start_time": "2018-04-09T19:09:42.252216Z"
    },
    "code_folding": [
     61,
     68
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAETCAYAAADah9Z7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4VFX++PH3vVMzM6kwEDqEjmAB\nBAvNCrpiV7Ct38WyKi6LuyrIiqioCKvurvioqOvXnyCuCLhfV7eoWJC6ivQiICEkkIQ00jPtnt8f\nkwyJBEhIJhNmPq/nyZPJ3HI+Z5J8zr3n3nuOppRSCCGEiAl6pAMQQgjRciTpCyFEDJGkL4QQMUSS\nvhBCxBBJ+kIIEUMk6QshRAyRpC8abNKkSRQWFjZqm61btzJlypSTrnfNNddQUlJyqqG1WqWlpfzy\nl79s9Hat7fN45ZVX+OKLLyIdhmgGkvRFg61evbrR2wwaNIiXX375pOv93//9HwkJCacSVqtWXFzM\n1q1bG71da/s81q9fj9/vj3QYohmYIx2AOD089thjANx555288cYb3HbbbZx55pn8+OOP/O53v8Ns\nNrNgwQK8Xi+FhYVce+21TJ06lfXr1zN79mw++eQTpk+fjsvl4scffyQnJ4e0tDReeuklnE4nffv2\nZe3atXz99dd8/vnn6LpORkYGFouFuXPn0qdPHzIyMpgxYwbFxcW43W6UUlx99dVcf/31dWItLS3l\n2WefZffu3fh8Ps4//3weffRRzGYzAwcO5JJLLmHXrl288MIL3HLLLXV+9ng8zJs3j8rKSiwWC1On\nTmXUqFEsX76cpUuXUllZicvlYuHChXXKXLp0KR988AE+n4/i4mLuuecebr31Vh577DGqqqq45ppr\nWL58OSaTKbRNYWEhjz32GAcOHCApKQm3203v3r35zW9+E/o8HnjgAf7nf/6HcePGAfDCCy+glOKR\nRx7hww8/5P3338cwDJKSkpg5cyY9e/Y84edc2/Tp0zly5AiZmZmMGTOGG2+8kaeffpqKigoOHz5M\nv379+POf/8zSpUvZtm0b8+bNw2QyMXr0aF544QW+++47AoEAAwYM4PHHH8flcoXjT080NyVEA/Xp\n00cVFBQopZS66KKL1CuvvKKUUsowDHX77ber9PR0pZRSOTk5qn///qqgoECtW7dO/eIXv1BKKTVt\n2jQ1YcIE5fF4lNfrVddee61aunRpnX0vW7ZMDRkyRGVnZyullHr66afVo48+qpRS6uabb1bvvfee\nUkqpvXv3qrPOOkstW7bsmDinT5+u3n33XaWUUn6/Xz388MPqjTfeCJXz0Ucf1alTzc+FhYXq/PPP\nV5s2bVJKKbV79241bNgwdeDAAbVs2TJ17rnnqtLS0mPKKysrUzfffLMqLCxUSim1ceNGdfbZZyul\nlMrMzAy9/rmHHnpIzZs3TymlVG5urrrwwgvVyy+/XOfzWLp0qbr33ntDdRk5cqRKT09X69evV7fe\nequqqKhQSin17bffqiuuuOKkn3Nt06ZNU3feeWfo5+eff179/e9/V0op5fV61VVXXaX+/e9/K6WU\nuv3229W//vUvpZRS8+fPV88//7wyDEMppdSLL76oZs2aVW8dResjR/rilA0dOhQATdN4/fXX+frr\nr/nkk0/46aefUEpRWVl5zDYjR47EarUC0KdPH4qLi49Z54wzziA1NRWAAQMG8Pnnn1NcXMyWLVtY\ntGgRAD179uS8886rN66vv/6arVu3snTpUgCqqqrqjfvnP2/ZsoWuXbty1llnAdC7d28GDx7Mf//7\nXzRNo2/fvvUezTqdTl5//XW++eYb9u/fz65du6ioqDjOp3bUN998w0cffQRAu3btQkfztV1xxRXM\nmzePvLw8duzYQbdu3ejevTtLliwhIyODiRMnhtYtLi7myJEjQMM+Z4AhQ4aEXj/yyCOsXr2aN998\nk/3793P48OF66/H1119TWlrKmjVrAPD5fLRp0+ak9RWtgyR9ccocDgcAFRUVXHfddVx66aUMHTqU\nG264gS+++AJVz7BOdrs99FrTtAavU9MtUnv92l0ltRmGwV/+8hd69uwJQElJCZqmHRP3z382DOOY\nfSml8Pv9WCyWY7arkZOTw4QJE7j55psZMmQI48aN46uvvqp33drMZnOd+uj6sZfYHA4HY8eO5ZNP\nPmHjxo3cdNNNoVivueYaHnnkkdDPhw8fJjExEWjY51y77gC/+93vCAQCXHHFFYwZM4bs7Ox6tzMM\ngxkzZjB69GgAysvL8Xg8J62vaB3kQq5oMJPJVO/FvIyMDMrKypg6dSoXX3wx//3vf/F6vfUm0VPl\ncrkYPHgwy5cvByAzM5O1a9fWSeY1RowYwTvvvINSCq/Xy/333x86QziRs846i/T0dLZs2QLAnj17\n+O677xg2bNgJt9u2bRspKSk88MADjBw5MpTwA4EAZrOZQCBQb/IcPXp06GykqKiIL774ot763Hzz\nzSxfvpyNGzcyduxYAC688EI+/fRTDh8+DMD777/PnXfeedI6nsiqVauYPHkyV155JZqmsXnzZgKB\nAFD3dz9ixAjee++90O945syZvPTSS00qW7QcOdIXDXbZZZdx66238uqrr9Z5v2/fvowZM4YrrriC\nhIQEunbtSq9evcjIyAh1MTSHuXPn8oc//IHFixfTvn17OnfuXOeItsYf/vAHnn32WcaPH4/P5+OC\nCy7g7rvvPun+U1JS+Mtf/sLs2bOpqqpC0zTmzJlDjx492Lhx43G3u/DCC1m6dCnjxo0jLi6OM888\nk5SUFDIyMujWrRsDBgzgiiuu4P333yc5OTm03WOPPcbjjz/O+PHjSUpKomPHjvXWZ+DAgZjNZsaO\nHYvNZgOC3Tf33HMPkyZNQtM0XC4Xr7zySr2NRkM99NBDTJ48mcTEROLi4jj33HM5cOAAABdddBFz\n587F5/PxwAMPMHfuXK677joCgQD9+/dn+vTpp1yuaFmaOt55nxCtzGuvvcbll19Oz549KS0t5eqr\nr+bNN9+kV69ekQ7tlLz33nsMGDCAc845B6/Xy6233spvfvObULeJEOEgR/ritNG9e3ceeughdF0n\nEAhwzz33nLYJH6BXr17Mnj0bwzDw+XyMGzdOEr4IOznSF0KIGCIXcoUQIoZI0hdCiBjSqvv08/JK\nm7R9crKDoqKTPyQTTWKxzhCb9ZY6x47G1tvtjj/usqg+0jeb6394J5rFYp0hNustdY4dzVnvqE76\nQggh6pKkL4QQMUSSvhBCxBBJ+kIIEUMk6QshRAyRpC+EEDFEkr4QQsSQqEz6Zb5yluz+O/kVhZEO\nRQghWpWoTPr7iw/wTdYa1hzYEOlQhBCnCY/Hwz/+8fdGb7dp0w/s3bunwet//PFH3HXXHdx77/+w\nevW39a4TCAR4/PFHWbduTaPjOZmoTPrx1uA8pkWV9c8LKoQQP1dYWHBKSf/TTz8mPz+vQesWFOSz\ndOnfeO21v/LSS6+wYMEreL3eOuscPJjFgw/ew86dOxodS0OEbeyd5cuXhyZ99ng87Ny5k4ULF/Ls\ns89iMpkYMWIEDz74YFjKTrQlAFBUeSQs+xdChNeSL/fy3a7Dx7xvMmkEAqc2Gvy5/dpx88XHn3/h\n3XffZv/+dP73f9/kpptu4fnnnw5NKD916iP07NmL5557iqysTDweDzfdNJHu3dNYv34tu3fvonv3\nNFJTU08Yw86d2xk06CysVitWq5VOnbrw00976N//jNA6FRUVTJs2k/fe+3+nVM+TCVvSv/7667n+\n+usBeOqpp7jhhhuYNWsW8+fPp0uXLtx7773s2LGDAQMGNHvZ8RYXGhpFVXKkL4RomF/+chI//bSX\nX/3qHl599WWGDBnGddfdSGbmAZ577ilefPFlNm36gQUL3kHTNP7733X069ef4cPP55JLLj9pwofg\nJPJOpyv0s8PhoKysrM46vXv3afa61Rb2UTa3bt3K3r17+f3vf88777xD165dgeDkymvWrAlL0jfp\nJuKtLuneEeI0dfPFveo9Kne745s8+m5D7Nu3lx9++J4VKz4DoLS0BIfDyZQpv2fevGepqCjn8suv\nOO72y5Z9wFdfrQBg1qxncLvbAeB0OqmoODpaZkVFBfHxxx8RMxzCnvQXLFjA5MmTKSsrw+U62sI5\nnU4yMzNPuG1ysuOURpfLK6rEU2Gh0n+Etm1dTZos+nR0omFVo1ks1lvq3Hx8vnhMJg23O55+/fow\ncOBAxo8fT0FBAR9++CFKVZKVtY+33lqAx+Nh9OjR3H77BOLirCQk2OvEdd99d3PffXcfU8aIEcN5\n++0FJCRY8Xq9ZGVlMGzY2aEJ72uz2y0kJsaF9ttc9Q5r0i8pKSE9PZ3zzjuPsrIyysvLQ8vKy8tJ\nSEg44fanOm72lp/yqSg1YUr2kZmTR5w57pT2czpqqSOh1iYW6y11bl6GYaWy0sNTTz3Lbbf9kuef\nn82iRYupqChn0qR7ATuZmYe44Yab0HWdCRNuo6iokrS0vsydOw+HI5nu3XucpBQ71157EzffPBHD\nMLjrrvsoKfGyYcNqtmzZxK9+dU9ozaoqH8XFleTllTa63idqIMI6R+6KFStYu3Ytjz/+OADXXHNN\nnT79Bx98kLPOOuu425/qL/dAbinPfvW/mNtlMXP470l1tj+l/ZyOYjERQGzWW+ocO5oz6Yf1SD89\nPZ3OnTuHfn7qqad4+OGHCQQCjBgx4oQJvymS420orx2AI56SmEr6QghxImFN+nffXbdP6+yzz2bJ\nkiXhLBIAV5wFLRBM+sWekrCXJ4QQp4uofDhL0zScpuBF42KvJH0hhKgRlUkfINEW7NM6IvfqCyFE\nSNQm/ZS4JADyKyTpCyFEjahN+m5XAkpp8oCWEELUErVJP8UVBz4rJT7p0xdCnFxjR9n85z//wapV\n3zSpzKysTO6//y4eeOBuXnhhDoZh1Lve559/zpNP/qFJZdWI2qSfVH3bZkWgjDA+iiCEiBKNHWXz\nyivHM2LE6CaVOX/+S9xzz/28+upbKKX49ttjG5E///kFXnzxRZSqv0ForLAPwxApKfF2lM+GQTHl\n/gpcFmekQxJCNNDyvZ+w8fDWY9436RoB49QO4s5pN4jre1113OW1R9k0DINt27ZQWVnJ9Okz+fe/\nP2XXrh2UlBTTq1cfZsyYxV//uoA2bdrQtWt33nvvXSwWM4cOHeSSSy7nzjvvalBMP/64i3POGQLA\needdwH//u57Roy+qs86gQWcyfvwVvPvuolOq989F8ZG+FeUNjmch9+oLIU7ml7+cRPfuPUJDIXTr\n1oPXX38bt9tNfHw8f/7zq7z11kK2b99KXl7dYZ9zc7N55pl5LFjwDosXv9vgMpVSobHBHA4n5eVl\nx6xzySWXN+v4YVF7pJ/ksqF8Rx/Q6uTqEOGIhBANdX2vq+o9Km/JYRi6du0GgM1mp6ioiFmzZuBw\nOKisrMTv99dZNy2tF2azGbPZjM1mr7MsKyuT55+fDcC4cVdy1VXXhpbp+tHj7oqK8jqDUoZL1CZ9\ns0knTnfiR470hRAnp2l6nX5zXQ8eXa9bt5rDh3N5+uk5FBUVsXLlV8dcJzzRgXjnzl145ZU36l3W\nu3dffvjhewYPHsq6dWsYPHho0ytyElHbvQOQUD2D1hFJ+kKIk0hOTsbn8/Pqqy/Xeb9//zM4dOgg\nkyffw8yZ0+jYsVODp0c8mQcfnMrbb7/Br3/9K3w+H2PGXALAQw9NxufzNUsZPxfWUTabqqmncX/6\nZBV7HR9zfupwbh9wQzNF1brJKISxQ+ocO5pzlM2oPtJv50oGoKBc5soVQgiI8qSfmpSEMjTp3hFC\niGpRnfTbJjpQPhul/tg7HRRCiPpEddJvk2gHn40qowKjmZ5mE0KI01nUJ33ltaMwKPed2ny7QggR\nTaI66bdNikP5gk/lSr++EEJEedJ32C3ogTgAij0yxLIQ4vgaO8pmjU2bfmDv3j2N2qaoqIiJE6/H\n4/Ecs6yhI2+eqqhO+oBMmyiEaJDGjrJZ49NPP27Uw1rr16/ld7+bTGFhQb3LGzLyZlOEdRiGBQsW\n8OWXX+Lz+bjlllsYNmwY06dPR9M0evfuzaxZs+qMPREOCdZ4KoGCCrlXX4jTRd6Hf6P0+++OeT/D\npBMInNqRb/zQc3HfNPG4y2uPsnnTTbfw/PNPU1wc7CGYOvURevbsxXPPPUVWViYej4ebbppI9+5p\nrF+/lt27d9G9exqpqaknjUPXNf7851e566476l1e38ibN9549SnU+DjlN9uefmb9+vVs3LiR999/\nn4ULF5KTk8OcOXOYOnUqixcvRinFihUrwlV8SIo9+IBWbln9raoQQkDdUTbfffdthgwZxvz5C3j0\n0T/wwgtzqKgoZ9OmH3j22T/y4ovz0XUT/fr1Z/jw87n//ikNSvgA5557HomJScdd3pCRN5sibEf6\nq1atok+fPkyePJmysjIeffRRlixZwrBhwwAYNWoUq1ev5rLLLgtXCAC0c6aw04D8yqKwliOEaD7u\nmybWe1TeUsMw7Nu3lx9++J4VKz4DoLS0BIfDyZQpv2fevGepqCjn8suvOO72y5Z9wFdfBQ9qZ816\nBre7XYPLDvfIm2FL+kVFRRw6dIjXX3+drKws7r///jotmNPppLT0xL+85GQHZrOpSXF075DC1+k2\nSizFJxyPIprESj1/LhbrLXVuPj5fPCaThtsdT79+fRg4cCDjx4+noKCADz/8EKUqycrax1tvLcDj\n8TB69Ghuv30CcXFWEhLsdeK67767ue++u09Ynsmk43bHY7PZ6rw/cOAZ7Nu3g+HDh7Np03eMHHkB\n0Hz1DlvST0pKIi0tDavVSlpaGjabjZycnNDy8vJyEhISTriPoqKm3Vvvdsdj1sDwxFFqLSEn9wgm\nvWmNSGsnA1LFDqlz8zIMK5WVHp566lluu+2XPP/8bBYtWkxFRTmTJt0L2MnMPMQNN9yErutMmHAb\nRUWVpKX1Ze7ceTgcyXTv3qPB5QUCBnl5pdhsXtLT97Fs2RIefng699zzIPPmPYvP56Nbt+4MHhxM\n+s014FrYRtn86quvePfdd3n77bc5fPgwt99+Oz179uRXv/oVw4cP54knnuC8887jyiuvPO4+mvrL\ndbvj+X7rIZ779i3MbbKZfcFjoT7+aBWLiQBis95S59jRnKNshu1I/6KLLuK7777jxhtvRCnFE088\nQefOnZk5cyYvvfQSaWlpjB07NlzFh7RNsqM8wZlsCiqLoj7pCyHEiYT1ls1HH330mPcWLWqeyX0b\nymm3YAkEL4QUVsnFXCFEbIv6h7MAEi2JABRUFUY4EiGEiKyYSPopcXKvvhBCQIwk/Q4JbQHILZcj\nfSFEbIuJpN8+0YXy2ijySJ++ECK2xUTSb5sUh/LaKQ+UymQqQoh6NXaUzX/+8x+sWtU8g6G9/PKL\n/P3vS4953zAM/vjH55gwYQIPPngvWVmZTS4rJpK+O9GO4YlDYVAs4+oLIerR2FE2r7xyPCNGjG5S\nmUVFRfz+91NYtWplvcu//fZrvF4vH3zwAffd9xteeeVPTSoPwnzLZmvRJtGO8gTH1S+oKiLZfvzB\njoQQkbfmy5/Yt+vwMe/rJh3jFEfZTOvXjgsu7nnc5bVH2TQMg23btlBZWcn06TP5978/ZdeuHZSU\nFNOrVx9mzJjFX/+6gDZt2tC1a3fee+9dLBYzhw4d5JJLLufOO+9qUEyVlRVMmnQv69atrnf5li2b\nGD78fAAGDhzErl07G1/xn4mJI3271YxNyb36Qojjqz3KJkC3bj14/fW3cbvdxMfH8+c/v8pbby1k\n+/at5OXVbZByc7N55pl5LFjwDosXv9vgMjt27MQZZww87vLy8nKczqMDrum6jt/vb2TN6oqJI32A\nRGsSRUB+hdzBI0Rrd8HFPes9Km/JYRi6du0GgM1mp6ioiFmzZuBwOKisrDwm8aal9cJsNmM2m7HZ\n7HWWZWVl8vzzswEYN+5Krrrq2gbH4HQ6qag4OgaZUgqzuWlpO2aSfltHCkVATll+pEMRQrRCmqaj\nat3ooevBEYHXrVvN4cO5PP30HIqKili58it+PmRZ9eDB9ercuQuvvPLGKcU0aNBZrF79LRMnXs+2\nbVtJS+t1SvupLSa6dwBSXW0AOCz36gsh6pGcnIzP5+fVV1+u837//mdw6NBBJk++h5kzp9GxY6dG\nTY94KmbPfoKcnBxGjboIq9XKxIkTmT//JaZM+V2T9x22UTabQ3OMslmzj683HmRJ7mvExzmYO3pG\nc4TXKskohLFD6hw7mnOUzZg50m+bZEd54ygPlMi9+kKImBUzSd+dGBe6V7/EG3tHCkIIATGU9FMS\n7FBzr77MlyuEiFExk/QtZh27FuznkiGWhRCxKmaSPgTv1QfIr5AjfSFEbIqppO+OSwHgYMmxj3cL\nIUQsiKmk3ynBjVKQWxHee2yFEKK1iqmk3y7JhfLEUeSRPn0hRGwK6zAM1113HS5XcLCgzp07M2HC\nBJ599llMJhMjRozgwQcfDGfxx2ibaEftdVJlz6fSX0Wc2X7yjYQQIoqELel7PB6UUixcuDD03jXX\nXMP8+fPp0qUL9957Lzt27GDAgAHhCuEY7VMcqCoHAHkV+XRN6NxiZQshRGsQtqS/a9cuKisrmTRp\nEn6/n9/85jd4vV66du0KwIgRI1izZs0Jk35ysgOz2dSkOGo/jty2rQtzIPhzpbnshI8qn86itV4n\nE4v1ljrHjuaqd9iSvt1u56677uKmm25i//793HPPPSQkJISWO51OMjNPPPVXUVHFCZefTH3jVSRb\ng6Nt7sk5QF9HvybtvzWSsUlih9Q5djTn2DthS/o9evSgW7duaJpGjx49iI+P58iRI6Hl5eXldRqB\nltLB1Y4iILM4t8XLFkKISAvb3TtLly7l+eefByA3N5fKykocDgcHDhxAKcWqVasYOnRouIo/rm7J\nbpShkVsu4+oLIWJP2I70b7zxRh577DFuueUWNE3jueeeQ9d1Hn74YQKBACNGjOCss84KV/HH1bFt\nPGqPgyK9EKUU2olmPxBCiCgTtqRvtVp58cUXj3l/yZIl4SqyQTq0caC2OvHHHabMV0681XXyjYQQ\nIkrE1MNZAO6kOPA4AcirlC4eIURsibmkbzbpuPTgwGu55TIcgxAitsRc0gdo52gLyB08QojYE5NJ\nv0tiewCySiTpCyFiS0wm/W4pblTARH5lQaRDEUKIFhWTSb+j24mqclAaOCKTpAshYkpMJv3UFAdG\nlRND81PsKYl0OEII0WJiMunbrWbsKjgEhNy2KYSIJTGZ9CE48BrIHTxCiNgSs0k/1eUGIKMoJ8KR\nCCFEy4nZpJ+W3BGAQ2VypC+EiB0xm/S7uVMwPHYKfIcjHYoQQrSYmE36Hdo6URXxeKmg1FsW6XCE\nEKJFxGzST3BYsfqDY/BklR2KcDRCCNEyYjbpA7jtqQDsK8yKcCRCCNEyYjrpd0/sBMDewhPP1SuE\nENEippN+3/adUAET2eVy26YQIjbEdNLv1j4eVemi1CjEZ/gjHY4QQoRdTCd9d3IcWmUiaIqccrlf\nXwgR/cKa9AsKChg9ejQ//fQTGRkZ3HLLLdx6663MmjULw4j86Ja6ppFsrn4yt/hghKMRQojwC1vS\n9/l8PPHEE9jtdgDmzJnD1KlTWbx4MUopVqxYEa6iG6VzfAcAducfiHAkQggRfmFL+nPnzmXixIm0\na9cOgO3btzNs2DAARo0axZo1a8JVdKP0adcVpSCzRO7VF0JEP3M4drp8+XJSUlIYOXIkb7zxBgBK\nKTRNA8DpdFJaWnrS/SQnOzCbTU2Kxe2OP+HyIf06s/RLB4VaHm3bukIxns5OVudoFYv1ljrHjuaq\nd1iS/rJly9A0jbVr17Jz506mTZtGYWFhaHl5eTkJCQkn3U9RUUWT4nC748nLO3Hj4jBpqIoE/PYc\n9mRlkWxPalKZkdaQOkejWKy31Dl2NLbeJ2ogwtK9895777Fo0SIWLlxI//79mTt3LqNGjWL9+vUA\nrFy5kqFDh4aj6EazWky4qB5bv1S6eIQQ0a3BSb+iooJdu3ahlKKiovFH4NOmTWP+/PlMmDABn8/H\n2LFjG72PcEl1BIdj+DE/I8KRCCFEeDWoe2ft2rU88cQTBAIB/va3v3H11VfzwgsvMGLEiJNuu3Dh\nwtDrRYsWnXqkYdQzuQvplZBeJGPwCCGiW4OO9F966SUWL15MQkIC7dq1Y9GiRcybNy/csbWY3qmp\nKJ+V3KrsSIcihBBh1aCkbxgGbrc79HOvXr3CFlAkdGsfj1GWSBVlFHtKIh2OEEKETYOSfmpqKl99\n9RWaplFSUsJrr71Gx44dwx1bi4l3WIkLBBu1fUfkIS0hRPRqUNJ/+umn+cc//kF2djaXXXYZO3fu\n5Omnnw53bC2qW3wXALbm7o1wJEIIET4NupDbpk0bXnrpJQBKS0vJyckJPWkbLc7skMbuAvipSO7g\nEUJErwYd6X/44Yc89thjFBYW8otf/IIpU6bwpz/9KdyxtagzurVHVboo9OdiqMgPBieEEOHQoKT/\n/vvvM23aND755BMuueQS/vGPf/Dtt9+GO7YW1S4pDrMnBUPzc6hMJlURQkSnBj+clZSUxDfffMOY\nMWMwm814PJ5wxtXiNE0j1R68OL0lR/r1hRDRqUFJv1evXtx3331kZWVxwQUX8Nvf/pZBgwaFO7YW\n19+dBsCOw/siHIkQQoRHg5L+tGnTGDhwICNHjmTBggVkZmaSmpoa7tha3OCuPYJz5lbKGDxCiOjU\noKR/7733cvDgQZKSgiNQXnzxxZjNYRmgM6K6tktAq0iiSjtCpb8y0uEIIUSza3DmnjNnTjjjaBV0\nXSPZlEqRVsD23HSGdhoQ6ZCEEKJZNehI/9JLL+XDDz8kMzOTQ4cOhb6iUVpSVwA2HtwT4UiEEKL5\nNehIv7S0lDfeeIPk5OTQe5qmtZp5bpvTkM592LDvX2SUyHAMQojo06Ck/9lnn7F27drQJOfR7Iwu\nHVA7HByx5BAwApj0pk3XKIQQrUmDune6dOlCcXFxuGNpFcwmnQTVAWXysSN3f6TDEUKIZtWgI31N\n0/jFL35B7969sVgsoffffffi4YoyAAAgAElEQVTdsAUWSX2SerLB8xPrDmxnUIeekQ5HCCGaTYOS\n/n333RfuOFqVC3sMZMOuz9hb/FOkQxFCiGbVoKQ/bNiwcMfRqvTp0B5tUzxl1lw8AR82k+XkGwkh\nxGmgwWPvxBJN03CbO4Nu8N/9uyIdjhBCNJuwPVYbCAR4/PHHSU9PR9M0nnrqKWw2G9OnT0fTNHr3\n7s2sWbPQ9dbZ7pzRtg+Hj+zk+6ydjOwZfeMMCSFiU9gy7ldffQXA3/72N6ZOncqf/vQn5syZw9Sp\nU1m8eDFKqVZ9n//o3oNQCg5U7o90KEII0WzCdqR/6aWXMmbMGAAOHTpEQkICa9asCV0fGDVqFKtX\nr+ayyy477j6Skx2YzU27T97tjj/l7ayrU/CYCzDHaSS7XE2KoyWdap1Pd7FYb6lz7Giueod11DSz\n2cy0adP4/PPPefnll1m9ejWapgHgdDopLS094fZFRRVNKt/tjicv78RlnEhHW1cyVCHL16/n6jNP\nj4vZTa3z6SoW6y11jh2NrfeJGoiwd6jPnTuX//znP8ycObPOxCvl5eUkJCSEu/gmOadDfwC2Hv4x\nwpEIIUTzCFvS//vf/86CBQsAiIuLQ9M0Bg4cyPr16wFYuXIlQ4cODVfxzeLCtP4oQyfHewClVKTD\nEUKIJgtb0r/88svZsWMHt912G3fddRczZszgiSeeYP78+UyYMAGfz8fYsWPDVXyzcFjtuIx2GPZi\ntmUdjHQ4QgjRZGHr03c4HPzlL3855v1FixaFq8iwOLPtGaw9ksOKPT8wqEvnSIcjhBBN0jpvkm9F\nLu8T7IL6qWy3dPEIIU57kvRPop2rDXGBFAKOPHZmHY50OEII0SSS9Bugf0p/NF2xYvfGSIcihBBN\nIkm/AS7pNQSA3SU/YkgXjxDiNCZJvwG6JXTCajgJOHPZnVUY6XCEEOKUSdJvAE3T6JPYD83sZ8Wu\nzZEORwghTpkk/QYa3eMcAHYd2UXAMCIcjRBCnBpJ+g3UN6UnJmUlEJ/N5j35kQ5HCCFOiST9BjLp\nJgYkD0Czevj3DrmLRwhxepKk3wiX9DgPgAO+nRSWVEU4GiGEaDxJ+o3QM6k7Tj0BPTmXrzYfiHQ4\nQgjRaJL0G0HXdC7oNBTNFODbjA0YhtyzL4Q4vUjSb6QLO50LQJUzg23pcs++EOL0Ikm/kdyONnSK\n64KeUMgXm3dHOhwhhGgUSfqnYHTXYWga/Fi2jcNHKiMdjhBCNJgk/VMwuP2ZmDChtz3Ip2vTIx2O\nEEI0mCT9UxBnjmNw+zPR7RWszdhGvhztCyFOE5L0T9HFXUYCoLfbzz/XZUQ4GiGEaBhJ+qeoa0Jn\neiX2wJSUz6rduykoloe1hBCtX1jmyPX5fMyYMYODBw/i9Xq5//776dWrF9OnT0fTNHr37s2sWbPQ\n9dO7zbmk6yj2bk1Ha5/OP9dncMflfSMdkhBCnFBYsu7HH39MUlISixcv5q233mL27NnMmTOHqVOn\nsnjxYpRSrFixIhxFt6iBbfvjjmuLuU02325PJ7eoItIhCSHECYUl6Y8bN47f/va3ACilMJlMbN++\nnWHDhgEwatQo1qxZE46iW5Su6cG+fd2Athks+kwmTxdCtG5h6d5xOp0AlJWVMWXKFKZOncrcuXPR\nNC20vLS09KT7SU52YDabmhSL2x3fpO1P5qrkMXy6/zMqO2Sx/Yce/HiolJFndwprmScT7jq3VrFY\nb6lz7Giueocl6QNkZ2czefJkbr31VsaPH88f//jH0LLy8nISEhJOuo+iJnaXuN3x5OWdvHFpqlEd\nz+ef+7/AmprJgo8cdG3jwGEP20d7Qi1V59YmFustdY4dja33iRqIsHTv5OfnM2nSJB555BFuvPFG\nAAYMGMD69esBWLlyJUOHDg1H0RFxcdeROMxx2Drvp7iynI++3RfpkIQQol5hSfqvv/46JSUlvPrq\nq9xxxx3ccccdTJ06lfnz5zNhwgR8Ph9jx44NR9EREWeO47JuY/DjIbFHFl9uyGJ35pFIhyWEEMfQ\nVCu+8tjU07iWPBX0BLw8uXYulb4qSn8YQXJcAk9NGobTbmmR8mvI6W/skDrHjlbfvROLbCYrY7tf\njE/56DukgMISD+/8c5fczSOEaFUk6TejCzsOJ8WezEG1g7TuZjbszuObTYciHZYQQoRI0m9GFt3M\n+LSx+JWf+N4/4rCbeH/FHrLyyiIdmhBCAJL0m9257c+hb3Ivdhfv4eIxJnx+g9f+vo0qrz/SoQkh\nhCT95qZpGhP7XodZN/N92VeMGdqO7IIKFn0ms2wJISJPkn4YtHO4GdftYoq9pVg776F7ajxrtuWw\nakt2pEMTQsS4qEz6fn+AnZuz8VRFrkvl0m5jaO9ox6pD67jy0njibCYWffYjWYelf18IETlRmfSz\nM4v5+l8/8kMEJzex6GZu6xd8GvmjjGXcNq47Xr/By8u2UFLhjVhcQojYFpVJPzE5DoCDByL7VGzP\npO78osflHPEUs8X3FeMv6EZ+cRWvfrQNf8CIaGxCiNgUlUk/PtGOzW4mOyvyQyGM7X4RfZJ7sTV/\nB4k9shna183uzCMyDLMQIiKiMulrmoY7NZ6iggo8Vb6IxqJrOv8zYCIui5P/2/spl4x00bW9i5Wb\nD7H0658wJPELIVpQVCZ9AHeqC4C8nMhfOE20JfA/A24hoAze3vkut/2iE+1THPxr/QHe+mSHdPUI\nIVpMFCf94IBDebmtY3Cm/m36MLHvdZT5ynnvp0VMmdCXnp0SWLc9lz8t2Ux5hM9IhBCxIfqTfnbr\nSPoAIzqdx9huF5NXWcB7e95jyk1ncE7vtuzMKOIPb6xj3fYc6ecXQoRV1Cb9+EQ79jgLeTmtJ+kD\njE8by7ntB5NecoBFP/6N+64ZwA2j06jyBnjjHzt48YNNHMovj3SYQogoFbVJX9M0OnROpORIVcQv\n5tamaRq397+R/il92Fawk/d3L+OK87oy++7hDEprw479Rcz863r++ukO8osrIx2uECLKRG3SB+jQ\nOQloHRdzazPrZu4eeAfdE7qyPmcDH+39lLaJdqbedCa/uWEQHds6Wb01hxlvrOOdf+2Up3iFEM0m\nMrN3t5COXRIByMsppXP35AhHU5fdbOP+s37Fnza8xpeZ36JpGtf2vJJzers5q2db1u/I5f9WpbNy\nczYrN2fTv1syF53TibN7t8Vsiuq2WggRRlGd9I8e6beufv0aLouTB8++m/mb3mTFgZXkVxRw5xm3\nYDNZOX9gKsMHtGfzT/l88X0WOzOK2JlRRILDwgWDOnDhwFQ6tnWiaVqkqyGEOI1EddJPSonDZje3\n2qQPkGxP4uEhk3lz60I252/nTz+8xq8H3UmyPQld1zint5tzers5mFfGys3ZrNmWzb/XH+Df6w/Q\nPsXBkD5uhvR10z01XhoAIcRJmZ588sknw7XzzZs388gjj3D99deTkZHB/fffz/Lly9myZQujR48+\naZKqaOLAZE6njd07csnLKePMoZ0wm01N2l+4WEwWhrY/mxJPCdsLdrE+ewNt49rQwdk+tE6C08qg\ntDZcNrQznd3BB88yckvZdeAIKzcfYtXWbPKPVOGIsxBn0dH12GoAnE5bk/9eTjdS59jR2Ho7nbbj\nLgvbkf6bb77Jxx9/TFxccPCzOXPmMHXqVIYPH84TTzzBihUruOyyy8JVfIg71UXW/iLycspaXb9+\nbWbdzK39bqRrQmeW7fmEt7Yt5PwO53Jj7/HYzfbQehaziWH92zOsf3s8vgDb9hXyw+48Nu3N54sN\nWXyxIQub1cSAbskM6tmGc3q1JdF1/D8AIURs0VSYngb6z3/+Q9++fXn00UdZsmQJI0eOZOXKlWia\nxhdffMHq1auZNWvWCffh9weafHS+Y/Mhlr67gfNGp3H51Wc0aV8t5WBJDi+vfZv0I5m0cSTzq3Nu\n5txOZ53wzMjnN9j6Uz7f78zlh125HMwL3uuvadCvWwrn9G2HO8lOSkIc7uQ4OrZ1YpILwkLEnLAd\n6Y8dO5asrKzQz0qpUNJyOp2Ulp68n72oqKJJMbjd8SS2icOVYGP9yn107pEcelK3NbPiZOrZ9/Ov\n/Sv4PONrXli9gIFt+nFD76tp52h73O26pMQx+NpB5OV15/CRSjbtyeeH3Xns2l/Izv2Fdda1mHU6\nu510S03gjO7J9O+WgsN++l7icbvjyctrvdduwkHqHDsaW2+3+/h5rsX+y3X96FFleXk5CQkJLVKu\n1Wbmoiv78o+/beHLT3dx451DMJlb/xGuWTczPm0sw9qfw992/51tBbvYUbib81KHMK77JbSJSznh\n9u2S4rj83C5cfm4Xisu9ZOSUUlzm4UiZh8NHKsk8XMaB3DLSs0v5euNBdE2jZ6cE+nRJok+XJHp2\nTDytGwEhRP1a7L96wIABrF+/nuHDh7Ny5UrOO++8liqazt1TGHBOR3ZsPMT3q/czfHRai5XdVO2d\n7Zhy9j1szNvKp/s+Y032d6zL2cB5qUO4pOtoUp3tTrqPRKeVM3u2OeZ9f8AgI6eUbemFbNtXwN6s\nYvZkFfPp2uCMYzaLCVecGVecFXeSndQ2DlJTHLRNjCMlwUaSyybPDAhxmmmxpD9t2jRmzpzJSy+9\nRFpaGmPHjm2pogE4f0wamfsK2bjuAN17t6V9x5Y502gOmqYxuN2ZnO0eyIbczfxz/+esyf6ONdnf\nMahtfy7pMppeST0afcum2aTTs1MiPTslcs2IHlRU+fnpUDG7M4+wP6eU0gov5ZU+sgvKyahntFJN\nA3di8PpAJ7eTNgl2El1Wklw24mxmLCYdi1nHZjFhtehyS6kQrUDYLuQ2h6b23f28H+xgRhEfv7+Z\n9h0TuO6Oc07bJGQogy152/niwDeklxwAoEt8Jy7uMpKxAy6kqLB5x+xRSlFU6iGnsILcwgoKSjwU\nllZRUFxFdkEFZZUnH9vIpGvYrSbsVhMWc7ARsJiCt5aaqr8sZhNmc/D9muVmsx5abjbpWKsbEJvZ\nFNpW1zXapDgpL6vCbNKrvzQs1dsG1ws2PnabCf00/b3/XCz2b8dinaF5+/RjKukD/Hv5NtJ35zPu\nhoH06H38i6KnA6UUPxXv56vMVWzO24ZCEW9zcVbbgQxtdzY9k7qja+HtflFKUVrh41B+OUWlHo6U\neygu81LlDeDzG/j8Aap8Aao8ASo9/ur3A3j8Bn6/gaEULfkXqAF2mznUIJh07WgjoFH9XrDR0HUN\nreZ9TcNiMWE1B89eLNWNk0nXURytg7n67MZq1nHYzTjjLMTZzCilCAQUAUMRKk7T8HiDn0ul11/9\neRn4AwaqVrwaGpoWXF/TQNc0NB0SXHZ8Xj9WiwmTXr0OoICAESxPoULb65qG2Rysm9mkB/dTsz9N\nQ9eD9bdUN66W6mtfNXUz6Ue3t5h0TKbgZ0h1eYah8PkNvP4AXl9wYiCrRa/+rHXqa2s1CO5TDx4A\nGCq4n2CZKvQ51PxeUtsnkJdfSs2Cms8l2knSb6D6Pqii/HI++Ot3JLVxcPOkc6PmIab8ykK+yVrN\nhrzNFFeVAJBojWdg2/4MajuAvsm9sJqsEY6yfkZ1QvT5DXwBA58vEPzuN/AHFAHDIBBQ+AMGHl9N\nUglgGMEkGjAU9jgrxSWV+AMGfr8KbW8YKpRIqrwBKjx+Kqr8+ANGcL/VCUapYIJRhsIfUPgNo1by\nCSY10TqZdA2TSaO6iT4+DfTqRq7m/z70u1cQqNPgVG+igdkUbHB0XQutW3M3Yk36MBShvzWt+khB\nq94+uB8Ns0nDajZhsQQb0+D6wb+54MFP8G/ZX31wcMmQTlw/qicgSb/BjvdBffXPXezaksPFv+hH\n30GpTSqjtUlp42DNns18n7uJrfk7KPMF79c362Z6Jfagf5s+DEjpSwdn+6g6Qgr3ab9SNUexxtHG\nyW8QCBihI2YAf3Xj5fEHqKjyU17po8LjR9eCiclcnSVq2hCrRcdhM2O3mrFagl1TFlPwqLj6YDfY\nGNUkGxSGEWwoXfF28vLL8PqCDVhtNd1aWvWOgtsFG0O/P9io1SSvmuRTk7R8fgOvL4DXb4TOdDQ0\nAkbwLMTnV9Wvgw2xBqGuNou5uguu+vkanz+Ap574ahgKAoHgvgzDQKs+86o5+6r5XINnLga6yYTP\n5z+6fXWj7z9Zo1z9GShF6CAguP+jyTmY2OueOdScofmrz2Rqzoyqdxn6veihuI/Wq+Z0JLge+KvP\ngnx+I1R2cDuqzyqDfyM1XZljzu7IRYM7A6fpLZutydALu7Nney7ffZtOr/7tTotbOBvKpJvol9Kb\nfim9MZTB/pIDbM3fyfaCXewq2sOuoj18xKck2RLpn9KHAW360i+5Nw5LXKRDb9U0Tau+ntB6hvJw\nu+PJS4itp61jtU+/OcVk0o9PtHPG4E5s+S6L71fvZ9ioxt/5cjrQNZ20xO6kJXbnmp5XUOwpYVfh\nHnYU/sjOwt2szf6OtdnfoWs6PRO7MyClLz0Su9IlvlOdoR+EENEjJpM+wODzu7J352F+WHuAovwK\nxlzZF3ucJdJhhVWiLYHhHYYwvMMQDGWQWXqQ7QW72F7wI3uPpLPnyD4geCrf3uGmS3xnusZ3pEt8\nJzq4UnFZnBGugRCiqWKyT79GeZmHLz7eyaEDR3Al2Ljs6gGkdk5sUpmRdqqnv6XeMnYX/URGaSYH\nSrLILD1IVcBTZ514i4tUZzvaO9y0c7hp52hLB2cqbezJET9TisXTfqlz7JALuQ3UkA/KMBQ/rMng\n+9X7AThrWBfOHdm91Q7DfDLN9U9hKIO8ygIySw+SVXqI7PJccspzKagqqnUjXZDdZKOjqwPuuDYk\n25NItiWSYk+mTVwKKbYkLKbwn0HFYjKQOscOuZDbjHRdY+iI7nTqlsSXn+5i0/pMMn4q4PyLetKp\nW9Jpm/ybStd02jvctHe4Gdr+7ND73oCPvMp8Dlfkk1uRx6GybA6W57C/5AD7ivfXu68EazxJtgSS\nbEkk2hJItMaTYIsnwRr8ire6iLfGY9Fj/s9RiLCT/7JqHbokcfOkoaz9eh/bfzjEPz/citms07Fb\nEj16t6X3gHZYrPJxWU0WOrk60MnVoc77PsNPUdURjniOUFRVTGFVEflVhRRUFlLkKSa7PJcDpQdP\nuO94i4skeyKJ1gRcVifxFhfxVledxsFldeI0OzDpsdkYC9FUMd+9U5+cg8Xs25XHgfRCivKDwztb\nbSb6DkzljHM6kty29V7QbK2nv0opyn0VFHtLKPGUBr97Syn1llHiLaXYU0Kxp4QjnmK8xsmHdYgz\nxxFvceK0OHFZHbRxJaEHzDgtDlwWJy6rC5fFic1kw2ayYDVZibe4oqqxaK2/63CKxTqDdO+EXWqn\nRFI7JXIBUFpcxa6tOezcdIitGw6ydcNBOnZN4oxzOtKjT1uZiKSBNE3DZXXisjqPOUuoTSlFVaCK\nUm85Zb5ySr2llFQ3DCXeUsqr36/5yq8qxFAG5DcgBjSSqq83JNjiQw1EnNmO3WQLfpnt2M12bKGf\nbdhMViy6JeIXq4VoDpL0TyI+0c65I7oz+Pyu7N+Tz/aNhziYcYRDB44Q57DQ78xU+p/VgcRkR6RD\njQqaphFnjiPOHEc7Tj42klKKSn8l9gSdzNw8yn0VwQbBW0aZrwJPwIM34MUT8HLEU0xBVRH7ivcf\nczH6pHGhYTFZsOlWbCYrcZY44kzBBsJqsmDVrVhNFuwmGzazDbvJjtMSh9PixGlxYDNZsZlsWE3B\n7cM9JpIQxyNJv4FMJp2e/drRs187igoq2LHpED9uzWHjukw2rsukfccEkts6SEyOIynFQbsO8Tjj\nbXJ0GGaapuGwOHC74tErG/ZAWcAIUOYrp9xXQbmvnEp/FVUBD1XV3z1+D5WBKjx+L56AB08g+N1r\n+PAGvFT5PZRU5OENnPoE3VbdUt042Kq7oKxYTVbMuhmLbsasmzFrJsy6GZNuwqyZMesmzLoluK5u\noW1FAp5yA2v1tke3M2MxBb8HtzVh0k3S0AhAkv4pSW7j4MJLejF8dA/2/ZjPzk2HOJRZTO6hkjrr\nOZxW2rZ3Eee0Yo+z4HBaaNPOhTs1PuofBGvNTLopeBeRrWlzKgSMQJ3GwFP9VdN41DQqFb7KWo1H\nTUPiqW5gvJR6y/AEvI0++2gsDQ2LbsaiW4KNg17dqFQ3CiYt+GXRzVhMFqzV65k0U2hdi24Jfplq\nXlc3NKH1zFh1c6hxslc3bBaTFZOmS8PTCkjSbwKz2USfM9rT54z2+P0BSo9UUVxUSWF+OYezS8nL\nKeXAvsJ6t3Ul2Ehu6yQ5xUFSGwcpbR2kuF3YZIrC04ZJN+HQHTRHx55SCr8K4Dd8eAN+/IafgPLj\nNwL4lZ+AEcBv+PEZ/lADY3XoFBSX4Al48QV8weXKjz/gx1+zreEnoAIElEGgenuf4cNnBPdZ4avE\nrwIEVADDCOBXgWaozfFpaNUNjI5JC559mGqdiZg0Ha36+8/PVDRNw2Gzofxa9dlNsFutppGq2d/R\nLw2d4GtN09DR0KvL1muVX3t9Df3o8up1axo6c3WMGtrRfZ6GjZhkmGZiNpuCSbytk+61xun3VPmp\nqvRRVemjvNRDXm4peTll5OeWkrmvkMyfNQquBBsJSXG44m24Emyh7qKkNg45O4himqZh0YJdO3EN\n/K8Mx50sNY2PL+DDZ/jwG4GjjY/hx2vUvF/dgAR8dRoYf3Wj4jV8+AI+Kv0eqgJV+AK+o41PdQNT\n8zqgDAxl4Av48BB8HTCCy/yGP+xnQE1Vp+GgZp4CrdbrYENh0nR0XUfXTOhooUaj9nqmWo3geR2G\nMrjdmc0eryT9MLPZzdjsZhKTg6NYpvV1h5Z5qnwcKaykKL+cwvxyCg4Hvx86cKTefVltJlwJdlwJ\nNlzxNhxOK854Gza7BavNhMVqQlMaXq8/+FquJ4hGqt34QOsYedVQRqhhSE6JI/twEZ6AF2/AW33W\n4sMb8BFQBqp63ZrvBgqljOAQ0hzdT8AIYNS8rl7fQNV5z/jZ2ZHf8Ffv7+h6Rs1rapet6pZbvW+/\nChDwe0Pb1cRUe3+1G7gkW6Ik/Whjs1to39FyzHy9Ab9BeZmH0uJgd9GRwgqOFFRQUlxFaXEVhXnl\nJ9232aJjj7NgtlRPQWgJNgoWq+noa1vwtdlswmzRMZmrpyc065jNpqM/m/Rg4xVnjtknlEXk6LWu\nBTitDhJt4e2CiqSaBidgBLCFadKjFk36hmHw5JNP8uOPP2K1WnnmmWfo1q1bS4ZwWjCZdRKS4khI\niqNTt+RjlnuqfJSXeako81Je5sFT6cfn9eP1BtCURkFBGRVlXjzV3Up+XwC/r/5JLBrLbNax2ExY\nrWYsVlOokTBVNw5mS3WDYdIwmXR0c3BikJrluuno5B5a9UQfNV+1Gxm9ZnuThq7rwZmRararNXUg\n1VMB+nyB4CQc1afWQpyOahq4cA5J0qJJ/4svvsDr9fLBBx+wadMmnn/+eV577bWWDCEq2OwWbHYL\nKfU8GXy8fl6lFH5f9VSE3kCokfB5AwSq56v1+4++DviCs0IFqmeK8lb58VT5qKr04/X68XkDlJd5\nCPiNFp3jtiFMpmADolfPQBWaHUnXjs5WZNKqG6xgA6XrWmjWJk2v3TBVz3BU877paCNVs69QA1Zr\nfryjDVNwH6FtqmdI0qrXDTVP1fPbHrt9cGHNjE5azUS4QHFBJaWllbXKOdoghnZba7q+uu8dne2r\nZmasozEcXV+rFWB9+6q7zs/8fL166lnfqseWfVRVpQ9Plb/e5bVjrT1zYp3V6p2nVzvushPRTrbj\nY9Zp7P7Dc/DSokl/w4YNjBw5EoCzzz6bbdu2tWTxMU3TtFD3Ds08ioRhGEcbi1rfA4Hg3LZGoLpR\n8RkYNdP0GTXzkQa/BwIGRkCFtjVqtjWC7xuGOrptzWTqodcKs9lEVZUvVF5N2So4x2CduU19PoNA\nZXCd5joDEqK5DRraiRGX9m72/bZo0i8rK8PlcoV+NplM+P1+zOb6w0hOdjS5D/lEY1BEq1is86mq\naQzqNi7VDdLPGibDUKHGKPReoPqinEH1vKuqTsOk1NH91KwfnIA9uKx2HMHvhPYBhMoP7qP2ekf3\nH4q1Oo4T7bdmzt2ahrC+MkPvV7eHqs52dScOr3NnTe2X9Zz91S2v1h7USdapXZ9aL+ru5uh8tDQg\nvmN3Xf/pakPOYo+/TuNOgX++n7Te7jr/y831f92iSd/lclFefvQipGEYx034AEVFFU0qLxYHZ4rF\nOkML1VsDzaxhNreOawax+LuOtTrX1LU5B1xr0ScLBg8ezMqVKwHYtGkTffr0acnihRAi5rXokf5l\nl13G6tWrmThxIkopnnvuuZYsXgghYl6LJn1d13n66adbskghhBC1nH4DRwghhDhlkvSFECKGSNIX\nQogYIklfCCFiiCR9IYSIIZpSDXnmTAghRDSQI30hhIghkvSFECKGSNIXQogYIklfCCFiiCR9IYSI\nIZL0hRAihkjSF0KIGNKio2y2hFiafN3n8zFjxgwOHjyI1+vl/vvvp1evXkyfPh1N0+jduzezZs1C\n16OvbS8oKOD666/n7bffxmw2x0SdFyxYwJdffonP5+OWW25h2LBhUV1vn8/H9OnTOXjwILquM3v2\n7Kj/XW/evJkXXniBhQsXkpGRUW9dX3nlFb7++mvMZjMzZszgzDPPbFwhKsr85z//UdOmTVNKKbVx\n40Z13333RTii8Fm6dKl65plnlFJKFRUVqdGjR6tf//rXat26dUoppWbOnKk+++yzSIYYFl6vVz3w\nwAPq8ssvV3v37o2JOq9bt079+te/VoFAQJWVlamXX3456uv9+eefqylTpiillFq1apV68MEHo7rO\nb7zxhrrqqqvUTTfdpJRS9dZ127Zt6o477lCGYaiDBw+q66+/vtHlRE8TWS2WJl8fN24cv/3tb4Hg\n3KImk4nt27czbNgwAFnty2sAAAniSURBVEaNGsWaNWsiGWJYzJ07l4kTJ9KuXTuAmKjzqlWr6NOn\nD5MnT+a+++5jzJgxUV/vHj16EAgEMAyDsrIyzGZzVNe5a9euzJ8/P/RzfXXdsGEDI0aMQNM0Onbs\nSCAQoLCwsFHlRF3SP97k69HI6XTicrkoKytjypQpTJ06FaUUmqaFlpeWRtd8osuXLyclJSXUsANR\nX2eAoqIitm3bxl/+8heeeuopHn744aivt8Ph4ODBg1xxxRXMnDmTO+64I6rrPHbs2DpzhtdX15/n\nt1P5DKKuT7+xk6+f7rKzs5k8eTK33nor48eP549//GNoWXl5OQkJCRGMrvktW7YMTdNYu3YtO3fu\nZNq0aXWOdKKxzgBJSUmkpaVhtVpJS0vDZrORk5MTWh6N9X7nnXcYMWIEv//978nOzubOO+/E5/OF\nlkdjnWurfa2ipq4/z2/l5eXExx9/EvR699tsEbYSsTT5en5+PpMmTeKRRx7hxhtvBGDAgAGsX78e\ngJUrVzJ06NBIhtjs3nvvPRYtWsTChQvp378/c+fOZdSoUVFdZ4AhQ4bw7bffopQiNzeXyspKzj//\n/Kiud0JCQiihJSYm4vf7o/7vu7b66jp48GBWrVqFYRgcOnQIwzBISUlp1H6jbpTNmrt3du/eHZp8\nvWfPnpEOKyyeeeYZ/vWvf5GWlhZ67w9/+APPPPMMPp+PtLQ0nnnmGUwmUwSjDJ877riDJ598El3X\nmTlzZtTXed68eaxfvx6lFA899BCdO3eO6nqXl5czY8YM8vLy8Pl8/PKXv2TgwIFRXeesrCx+97vf\nsWTJEtLT0+ut6/z581m5ciWGYfDYY481uuGLuqQvhBDi+KKue0cIIcTxSdIXQogYIklfCCFiiCR9\nIYSIIZL0hRAihkjSFxF17bXXAsH77z/44IMGb7dkyRIuuugi5s6dW+f9iy++mKysrGaNsbbHHnuM\ngwcPAnDPPfeQm5sblnI++OADPvnkk7DsW8Q2SfoiYtLT00MjoP7www8MGTKkwdt+8sknzJ49m2nT\npoUrvHrV3CcP8Oabb9K+ffuwlLNx40a8Xm9Y9i1iW/SOTyBatbvuuovdu3djNpu55pprSE9PJz09\nneXLl9dZb9myZfzv/2/v3kKq2roAjv+9pXZRjDSilBRCQSIlUFNwp0lkIF5CNLGoBBMtM+1iaV5S\nvEH1oBiRKEX1IJlIqGTeQjTRsjQoRR9MQ6xso2mG6XacBzmbrO8c4/uKPnL+nhZzrTnXHHvBWHNP\nNmOXlWFgYICzszMXLlygrKyMFy9ekJmZSWpqKhqNZlGfoqIient7MTU1JTMzEycnJ8bGxkhJSWFk\nZARjY2NOnjyJt7c3nz9/JjU1lb6+PgwMDIiKiiIoKIje3l7S0tKYm5vD1NSU3Nxc6urqePfuHdHR\n0dy+fZt9+/Zx8+ZNOjo6aGlpYWJiguHhYby8vMjIyADg0qVLPHjwACsrK6ytrfH19SUkJEQ/16mp\nKRITExkbGwMgLi4Oc3NzGhsbaW9vx9ramvXr15OVlcX09DRarZbDhw9z8OBBJicnOXPmDENDQ9ja\n2jI6OkpRUREbNmygoKCAjo4OdDodISEhHDp0iNHRUU6dOsX09DSGhoakpqbi4uLyax+08v/nf6wG\nqij/tby8PGltbZXJyUmJiIj47nxvb6/4+fmJVqsVEZGMjAzJy8sTEZHIyEh92dmv+fj4SHFxsYiI\nNDc3S2BgoIiIxMfHS2lpqYiIDA0NiZeXl7x//17y8/MlKytLREQ+fPggvr6+8urVK0lOTpaamhoR\nEamurpbKykr9+MPDw4uOKyoqRKPRyOTkpExPT4u3t7f09vZKQ0OD7N+/X2ZmZmR8fFx8fHykoqJi\n0Xzv3bsnGRkZIiIyMDCgj+/s2bP6a7Ozs6WtrU0/dxcXFxERyc3Nlfz8fBER6enpEScnJxkeHpY7\nd+5ITk6OiIjMzMxIZGSkdHZ2SmFhoVy/fl1EFko1l5SU/NiDUv4oantH+W0GBgZwdHSkv7+fLVu2\nfHe+s7MTHx8frKysAAgLC6O9vX3JcUNDQwHQaDSMjIzw8eNH2tvb9fWJbG1t2bZtG93d3Yva165d\ny65du+jo6ECj0ZCVlcX58+cxMTEhICDgX+/p6urK6tWrMTc3x9bWlomJCdra2vD392fFihVYWlri\n5+f3H/vV19cTGxvL06dPiYuL++6a5ORkZmZmuHbtGleuXGF6ehqA1tZWAgMDAdi6dSuOjo4APH78\nmMbGRgIDAwkNDWV0dJS+vj527NhBaWkpSUlJvH37lsjIyCU/S+XPo7Z3lN8iKiqKJ0+ecOTIEcbH\nxwHo6elZtL0zPz+/qI+I/FCZ7G9rsZiYmOj34b8eS6fT/WP7nj17cHV1pampiRs3bvDo0SOys7P/\n8Z6mpqb6YwMDA0QEQ0PD72L41ubNm6mtraWlpYWmpiZKS0upra1ddE1CQgIWFhb4+Piwd+9eqqur\n9XF+O38AnU7H6dOn2b17NwBarZaVK1diZmZGdXU1zc3N1NTUUFlZSVlZ2b/OT/nzqJW+8ltkZWXh\n6elJVVUVnp6eXL169bv9fDc3NxobG/UvhfLyctzd3Zcc+/79+wA8fPgQBwcHzM3N8fDw4O7duwAM\nDw/T1dWFi4vLonatVktDQwNubm4kJCTQ09NDeHg4J06c4OXLl8BCotXpdD8Uo5eXF3V1dXz58oWp\nqSmam5v19dH/duvWLQoLC/H39yc9PR2tVsvk5OSi+7S2thIfH4+fnx+dnZ3AQmL39PTUx9rX10d/\nfz8GBgZ4eHhQXl7O7Owsnz59IiIigu7ubgoKCqiqqiI4OJi0tDR9TMryolb6ym/x/PlzXF1dgYWE\n9ffWxNecnJw4evQoBw4cYHZ2FmdnZzIzM5cce3BwkMDAQFatWkVeXh6wUH00LS1N/2LJzs7GxsaG\nuLg4MjIyCAgIQKfTERMTg7OzMzExMaSkpFBcXIyRkRHJyckA7Ny5k+joaEpKSpach0ajoauri+Dg\nYCwtLbGxsVn0jQAWfrKamJhIQEAAxsbGHDt2DAsLCzw9Pbl8+TJr1qzh+PHjREREYGFhgb29PRs3\nbuTNmzfExsZy7tw5AgICsLOzY926dZiZmREeHs7r168JDg5mbm6OkJAQ3N3dsbOzIykpicrKSoyM\njEhPT18yBuXPo6psKsov8uzZMwYHBwkODmZ2dpawsDBycnJwcnL6KeNXVVWxadMmtm/fzsjICJGR\nkdTX1/9RfxSu/Hxqpa8ov4i9vT1FRUWUlZUhIgQFBf20hA/g4OBAeno68/PzGBoacvHiRZXwlSWp\nlb6iKMoyopYFiqIoy4hK+oqiKMuISvqKoijLiEr6iqIoy4hK+oqiKMvIX9MDnGNVA396AAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11540b470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "def stage_score_plot(estimator, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Parameters: estimator: GradientBoostingRegressor or AdaBoostRegressor\n",
    "       a         X_train: 2d numpy array\n",
    "                y_train: 1d numpy array\n",
    "                X_test: 2d numpy array\n",
    "                y_test: 1d numpy array\n",
    "\n",
    "    Returns: A plot of the number of iterations vs the MSE for the model for\n",
    "    both the training set and test set.\n",
    "    '''\n",
    "\n",
    "   #### YOUR CODE HERE ####\n",
    "    gdbr = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                     loss='ls',\n",
    "                                     n_estimators=100,\n",
    "                                     random_state=1,\n",
    "#                                      max_depth=3,\n",
    "#                                      subsample=1.0,\n",
    "#                                      min_samples_split=2,\n",
    "#                                      min_samples_leaf=1,\n",
    "#                                      min_weight_fraction_leaf=0.0     \n",
    "                                    )\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    model = gdbr.fit(X_train, y_train)\n",
    "    gdbr_predict = gdbr.predict(X_test)\n",
    "\n",
    "#     rf_score_mse = cross_val_score(rf, X_train,rf_y_hat_test_predicted, scoring='mean_squared_error').mean()\n",
    "\n",
    "    gb_test = []\n",
    "    gb_train = []\n",
    "    for preds in model.staged_predict(X_test):\n",
    "        # do what you would like with the different stages\n",
    "        gb_test.append(mean_squared_error(y_test, preds))\n",
    "#     return plt.plot(list(range(10,40)), gb_test)\n",
    "\n",
    "    for train_preds in model.staged_predict(X_train):\n",
    "        gb_train.append(mean_squared_error(y_train, train_preds))\n",
    "\n",
    "    plt.xlabel('# of boosting stages')\n",
    "    plt.ylabel('mse')\n",
    "    plt.title('training error at given rate');\n",
    "    plt.plot(gb_test, label = \"test - 0.1\")\n",
    "    plt.plot(gb_train, label = \"train - 0.1\")\n",
    "    \n",
    "    gdbr_1 = GradientBoostingRegressor(learning_rate=1,\n",
    "                                     loss='ls',\n",
    "                                     n_estimators=100,\n",
    "                                     random_state=1,\n",
    "#                                      max_depth=3,\n",
    "#                                      subsample=1.0,\n",
    "#                                      min_samples_split=2,\n",
    "#                                      min_samples_leaf=1,\n",
    "#                                      min_weight_fraction_leaf=0.0     \n",
    "                                    )\n",
    "    \n",
    "    model_1 = gdbr_1.fit(X_train, y_train)\n",
    "\n",
    "#     rf_score_mse = cross_val_score(rf, X_train,rf_y_hat_test_predicted, scoring='mean_squared_error').mean()\n",
    "\n",
    "    gb_test_1 = []\n",
    "    gb_train_1 = []\n",
    "    for preds_1 in model_1.staged_predict(X_test):\n",
    "        # do what you would like with the different stages\n",
    "        gb_test.append(mean_squared_error(y_test, preds_1))\n",
    "#     return plt.plot(list(range(10,40)), gb_test)\n",
    "\n",
    "    for train_preds in model_1.staged_predict(X_train):\n",
    "        gb_train_1.append(mean_squared_error(y_train, train_preds))\n",
    "\n",
    "    plt.plot(gb_test_1, label = \"test - 1.0\")\n",
    "    plt.plot(gb_train_1, label = \"train - 1.0\")\n",
    "    \n",
    "    return \n",
    "        \n",
    "        \n",
    "\n",
    "stage_score_plot(gdbr, X_train, y_train, X_test, y_test)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T23:17:23.134334Z",
     "start_time": "2018-04-09T23:17:23.040120Z"
    }
   },
   "source": [
    "8) Given your plot, explain the behavior of the test / train curves\n",
    "   for the two (0.1 and 1) learning rates. With a lower learning rate (0.1),\n",
    "   what is necessary to obtain a low test error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9. Using the `stage_score_plot` function, make a plot like you did above of\n",
    "    the MSE for `GradientBoostingRegressor` with `learning_rate=0.1`.\n",
    "\n",
    "    Add a horizontal line to indicate where the `RandomForestRegressor` test\n",
    "   error is at.\n",
    "\n",
    "   Your plot should look something like this:\n",
    "\n",
    "   ![gradient boosting](images/gradboost.png)\n",
    "\n",
    "   a. How many iterations does it take until Gradient Boosting beats Random Forest?\n",
    "\n",
    "10. Make a similar plot for `AdaBoost`. Again have the `learning_rate=0.1`\n",
    "    and add a horizontal line for the Random Forest test error.\n",
    "\n",
    "    Don't expect AdaBoost to be as smooth as the Gradient Boosting graph.\n",
    "\n",
    "    a. How many iterations does it take till AdaBoost beats Random Forest?\n",
    "\n",
    "11. As seen above when we compared two learning rates, suboptimal hyperparameters\n",
    "    can give rise to higher error\n",
    "    (MSE). Therefore, we aim to search for the set of hyperparameters that\n",
    "    would give us the lowest cross-validated train error. The search of these\n",
    "    hyperparameters is known as grid-search. For each hyperparameter, a set\n",
    "    of values are specified. The combination of the hyperparameters at different\n",
    "    values will constitute the search space. We try each possible combination\n",
    "    of parameters and find the combination which minimizes error.\n",
    "\n",
    "    Use `GridSearchCV` for to find the best `RandomForestRegressor`\n",
    "    and `GradientBoostRegressor` models respectively.\n",
    "    Remember to specify `n_jobs=-1` in `GridSearchCV` to use all the cores of your\n",
    "    machine and speed up your search.\n",
    "\n",
    "    Here are some values to start out with trying for hyperparameters for Random Forest:\n",
    "\n",
    "    ```python\n",
    "\n",
    "    random_forest_grid = {'max_depth': [3, None],\n",
    "                          'max_features': ['sqrt', 'log2', None],\n",
    "                          'min_samples_split': [2, 4],\n",
    "                          'min_samples_leaf': [1, 2, 4],\n",
    "                          'bootstrap': [True, False],\n",
    "                          'n_estimators': [10, 20, 40, 80],\n",
    "                          'random_state': [1]}\n",
    "\n",
    "    rf_gridsearch = GridSearchCV(RandomForestRegressor(),\n",
    "                                 random_forest_grid,\n",
    "                                 n_jobs=-1,\n",
    "                                 verbose=True,\n",
    "                                 scoring='mean_squared_error')\n",
    "    rf_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "    print \"best parameters:\", rf_gridsearch.best_params_\n",
    "\n",
    "    best_rf_model = rf_gridsearch.best_estimator_\n",
    "    ```\n",
    "\n",
    "    Feel free to change it to try a different set of parameters.\n",
    "\n",
    "    Note that this will take about 3-5 minutes to run. The total number of combinations is:\n",
    "    `2 * 3 * 2 * 3 * 2 * 4 * 1 = 288`. We are trying each of these possibilities!\n",
    "\n",
    "    a. What are the optimal parameters?\n",
    "\n",
    "    b. What is the MSE you get on the test set with these parameters?\n",
    "\n",
    "    c. How does this compare with the MSE with the default parameters?\n",
    "\n",
    "12. Go through the same process for `GradientBoosting`. Try several values for\n",
    "    these hyperparameters:\n",
    "\n",
    "    * `learning_rate`\n",
    "    * `max_depth`\n",
    "    * `min_samples_leaf`\n",
    "    * `max_features`\n",
    "    * `n_estimators`\n",
    "    \n",
    "    If you're unsure what values to include, take a look at sklearn's default. Include the default value and at least \n",
    "    one value less than and greater than the default value. Here's the [docs on Gradient Boosting](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier) where you can see the defaults.\n",
    "    If you want a set of starting parameters, [here](https://gist.github.com/pprett/3989337#file-grid_search-py-L115) is\n",
    "    a reference.\n",
    "\n",
    "    a. What are the parameters that give the optimal model?\n",
    "\n",
    "    b. How does the MSE for this model compare with the original MSE you got with Gradient Boosting\n",
    "    before tuning the parameters?\n",
    "\n",
    "13. **[Extra Credit]** Go through the same process for `AdaBoost`. Note you need to define different hyperparameters\n",
    "    in the base estimator to perform the gridsearch. This will also take much longer to run,\n",
    "    so feel free to just leave it running after you figure out some parameters to try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T16:14:31.320641Z",
     "start_time": "2018-04-09T16:14:31.292031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "clf_scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "clf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
